{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cEmzeUKFkPh"
      },
      "source": [
        "# Tarea para el Hogar 04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DenyKXkiJ5JN"
      },
      "source": [
        "##  1. Big Picture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-K2_ZsZGrVD"
      },
      "source": [
        "LightGBM es el algoritmo estado del arte para datasets estructurados.\n",
        "<br> La Bayesian Optimization es el estado del arte para optimización de hiperparámetros\n",
        "<br> Las soluciones a las tres competencias de la asignatura contendrán LightGBMs y Bayesian Optimizations\n",
        "<br> LightGBM ha aumentado en forma no darwiniana sus hiperparámetros en los últimos ocho años; no todos los existentes son útiles.\n",
        "<br> Es necesario lograr entender cuales son los hiperparámetros relevantes de LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9GkTOk5J9t3"
      },
      "source": [
        "## 2. Hiperparámetros del LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmEFy0ukKL5T"
      },
      "source": [
        "Los objetivos de esta tarea son:\n",
        "\n",
        "\n",
        "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
        "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
        "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
        "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
        "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
        "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yvlS6JQLRMd"
      },
      "source": [
        "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
        "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eydI4YNAsFaf"
      },
      "source": [
        "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
        "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzU4S0SeMcpp"
      },
      "source": [
        "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
        "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
        "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNptUgI_NWWG"
      },
      "source": [
        "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
        "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
        "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
        "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
        "\n",
        "\n",
        "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
        "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpUThBojODyK"
      },
      "source": [
        "El desafío de esta tarea es:\n",
        "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
        "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
        "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX0qg_c0yqob"
      },
      "source": [
        "#### 2.1  Seteo del ambiente en Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LpZCst5a7Zs",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLelftXa7Zt",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/dmeyf\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/dmeyf\" /content/buckets/b1\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/dmeyf2025-e4a2/competencia_01_crudo.csv\"\n",
        "archivo_destino=\"/content/datasets/competencia_01_crudo.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/competencia_01_crudo.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dseB4qb9RqUb"
      },
      "source": [
        "### Generacion de la clase_ternaria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCEnE_02RuIQ"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Tipe -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P863YZB9R1Ua",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "require( \"data.table\" )\n",
        "\n",
        "# leo el dataset\n",
        "dataset <- fread(\"../../Competencia 01/competencia_01_crudo.csv\" )\n",
        "\n",
        "# calculo el periodo0 consecutivo\n",
        "dsimple <- dataset[, list(\n",
        "    \"pos\" = .I,\n",
        "    numero_de_cliente,\n",
        "    periodo0 = as.integer(foto_mes/100)*12 +  foto_mes%%100 ) ]\n",
        "\n",
        "\n",
        "# ordeno\n",
        "setorder( dsimple, numero_de_cliente, periodo0 )\n",
        "\n",
        "# calculo topes\n",
        "periodo_ultimo <- dsimple[, max(periodo0) ]\n",
        "periodo_anteultimo <- periodo_ultimo - 1\n",
        "\n",
        "\n",
        "# calculo los leads de orden 1 y 2\n",
        "dsimple[, c(\"periodo1\", \"periodo2\") :=\n",
        "    shift(periodo0, n=1:2, fill=NA, type=\"lead\"),  numero_de_cliente ]\n",
        "\n",
        "# assign most common class values = \"CONTINUA\"\n",
        "dsimple[ periodo0 < periodo_anteultimo, clase_ternaria := \"CONTINUA\" ]\n",
        "\n",
        "# calculo BAJA+1\n",
        "dsimple[ periodo0 < periodo_ultimo &\n",
        "    ( is.na(periodo1) | periodo0 + 1 < periodo1 ),\n",
        "    clase_ternaria := \"BAJA+1\" ]\n",
        "\n",
        "# calculo BAJA+2\n",
        "dsimple[ periodo0 < periodo_anteultimo & (periodo0+1 == periodo1 )\n",
        "    & ( is.na(periodo2) | periodo0 + 2 < periodo2 ),\n",
        "    clase_ternaria := \"BAJA+2\" ]\n",
        "\n",
        "\n",
        "# pego el resultado en el dataset original y grabo\n",
        "setorder( dsimple, pos )\n",
        "dataset[, clase_ternaria := dsimple$clase_ternaria ]\n",
        "\n",
        "fwrite( dataset,\n",
        "    file =  \"./competencia_01.csv.gz\",\n",
        "    sep = \",\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3hL7tv8W4rn",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "setorder( dataset, foto_mes, clase_ternaria, numero_de_cliente)\n",
        "dataset[, .N, list(foto_mes, clase_ternaria)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSKhZRToy2F7"
      },
      "source": [
        "### 2.2 Optimizacion Hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kwPpHAtSmix"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp4-Bj3aYI8d"
      },
      "source": [
        "### 2.2.1 Inicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy8YTZfESxeJ"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gBq__iAdQliq",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "'jue sept 11 16:01:19 2025'"
            ],
            "text/latex": [
              "'jue sept 11 16:01:19 2025'"
            ],
            "text/markdown": [
              "'jue sept 11 16:01:19 2025'"
            ],
            "text/plain": [
              "[1] \"jue sept 11 16:01:19 2025\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7rdVrBojS1IV",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td> 716808</td><td>38.3</td><td>1446667</td><td>77.3</td><td>1446667</td><td>77.3</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>1322907</td><td>10.1</td><td>8388608</td><td>64.0</td><td>1928447</td><td>14.8</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A matrix: 2 × 6 of type dbl\n",
              "\\begin{tabular}{r|llllll}\n",
              "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
              "\\hline\n",
              "\tNcells &  716808 & 38.3 & 1446667 & 77.3 & 1446667 & 77.3\\\\\n",
              "\tVcells & 1322907 & 10.1 & 8388608 & 64.0 & 1928447 & 14.8\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A matrix: 2 × 6 of type dbl\n",
              "\n",
              "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
              "|---|---|---|---|---|---|---|\n",
              "| Ncells |  716808 | 38.3 | 1446667 | 77.3 | 1446667 | 77.3 |\n",
              "| Vcells | 1322907 | 10.1 | 8388608 | 64.0 | 1928447 | 14.8 |\n",
              "\n"
            ],
            "text/plain": [
              "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
              "Ncells  716808 38.3 1446667    77.3 1446667  77.3\n",
              "Vcells 1322907 10.1 8388608    64.0 1928447  14.8"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuPfQ7ksjwW3"
      },
      "source": [
        "### 2.2.2 Carga de Librerias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8BaSFlGfvma"
      },
      "source": [
        "Esta parte lleva varios minutos la primera vez en Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lVyxLaJ1j1J_",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cargando paquete requerido: data.table\n",
            "\n",
            "Cargando paquete requerido: parallel\n",
            "\n",
            "Cargando paquete requerido: R.utils\n",
            "\n",
            "Cargando paquete requerido: R.oo\n",
            "\n",
            "Cargando paquete requerido: R.methodsS3\n",
            "\n",
            "R.methodsS3 v1.8.2 (2022-06-13 22:00:14 UTC) successfully loaded. See ?R.methodsS3 for help.\n",
            "\n",
            "R.oo v1.27.1 (2025-05-02 21:00:05 UTC) successfully loaded. See ?R.oo for help.\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'R.oo'\n",
            "\n",
            "\n",
            "The following object is masked from 'package:R.methodsS3':\n",
            "\n",
            "    throw\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:methods':\n",
            "\n",
            "    getClasses, getMethods\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:base':\n",
            "\n",
            "    attach, detach, load, save\n",
            "\n",
            "\n",
            "R.utils v2.13.0 (2025-02-24 21:20:02 UTC) successfully loaded. See ?R.utils for help.\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'R.utils'\n",
            "\n",
            "\n",
            "The following object is masked from 'package:utils':\n",
            "\n",
            "    timestamp\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:base':\n",
            "\n",
            "    cat, commandArgs, getOption, isOpen, nullfile, parse, use, warnings\n",
            "\n",
            "\n",
            "Cargando paquete requerido: primes\n",
            "\n",
            "Cargando paquete requerido: rlist\n",
            "\n",
            "Cargando paquete requerido: yaml\n",
            "\n",
            "Cargando paquete requerido: lightgbm\n",
            "\n",
            "Cargando paquete requerido: DiceKriging\n",
            "\n",
            "Cargando paquete requerido: mlrMBO\n",
            "\n",
            "Cargando paquete requerido: mlr\n",
            "\n",
            "Cargando paquete requerido: ParamHelpers\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'ParamHelpers'\n",
            "\n",
            "\n",
            "The following object is masked from 'package:R.utils':\n",
            "\n",
            "    isVector\n",
            "\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'mlr'\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:R.utils':\n",
            "\n",
            "    resample, setThreshold\n",
            "\n",
            "\n",
            "Cargando paquete requerido: smoof\n",
            "\n",
            "Cargando paquete requerido: checkmate\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'checkmate'\n",
            "\n",
            "\n",
            "The following object is masked from 'package:DiceKriging':\n",
            "\n",
            "    checkNames\n",
            "\n",
            "\n",
            "The following object is masked from 'package:R.utils':\n",
            "\n",
            "    asInt\n",
            "\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'smoof'\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:R.oo':\n",
            "\n",
            "    getDescription, getName\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# cargo las librerias que necesito\n",
        "if(!require(\"data.table\")) install.packages(\"data.table\")\n",
        "require(\"data.table\")\n",
        "\n",
        "if(!require(\"parallel\")) install.packages(\"parallel\")\n",
        "require(\"parallel\")\n",
        "\n",
        "if(!require(\"R.utils\")) install.packages(\"R.utils\")\n",
        "require(\"R.utils\")\n",
        "\n",
        "if( !require(\"primes\") ) install.packages(\"primes\")\n",
        "require(\"primes\")\n",
        "\n",
        "if( !require(\"utils\") ) install.packages(\"utils\")\n",
        "require(\"utils\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
        "require(\"yaml\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz-6Qt6BUaA3"
      },
      "source": [
        "### 2.2.3 Definicion de Parametros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOdlKd7lUm2I"
      },
      "source": [
        "aqui debe cargar SU semilla primigenia\n",
        "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ASYkebOu2mF6",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- 4940\n",
        "PARAM$semilla_primigenia <- 200003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ezOhQdbA293o",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# training y future\n",
        "PARAM$train <- c(202102)\n",
        "PARAM$train_final <- c(202102)\n",
        "PARAM$future <- c(202104)\n",
        "PARAM$semilla_kaggle <- 314159 #Semilla para el modelo final que va a Kaggle, primeros números de pi que sean primos.\n",
        "PARAM$cortes <- seq(6000, 19000, by= 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jtB0Lub42rHO",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
        "# undersampling de 1.0  implica tomar TODOS los datos\n",
        "\n",
        "PARAM$trainingstrategy$undersampling <- 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OFxm-xiNUOJX",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Parametros LightGBM\n",
        "\n",
        "PARAM$hyperparametertuning$xval_folds <- 5\n",
        "\n",
        "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
        "PARAM$lgbm$param_fijos <-  list(\n",
        "  boosting= \"gbdt\", # puede ir dart, ni pruebe random_forest\n",
        "  objective= \"binary\", #default regression\n",
        "  metric= \"auc\", # default \"\" \n",
        "  first_metric_only= FALSE, # default FALSE\n",
        "  boost_from_average= TRUE, # default TRUE\n",
        "  feature_pre_filter= FALSE, # default TRUE\n",
        "  force_row_wise= TRUE, # para reducir warnings\n",
        "  verbosity= -100,\n",
        "\n",
        "  seed= PARAM$semilla_primigenia,\n",
        "\n",
        "  max_depth= -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
        "  min_gain_to_split= 0, # min_gain_to_split >= 0\n",
        "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
        "  lambda_l1= 0.0, # lambda_l1 >= 0.0\n",
        "  lambda_l2= 0.0, # lambda_l2 >= 0.0\n",
        "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
        "\n",
        "  bagging_fraction= 1.0, # 0.0 < bagging_fraction <= 1.0\n",
        "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
        "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  is_unbalance= FALSE, # Default FALSE\n",
        "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
        "\n",
        "  drop_rate= 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  max_drop= 50, # <=0 means no limit\n",
        "  skip_drop= 0.5, # 0.0 <= skip_drop <= 1.0\n",
        "\n",
        "  extra_trees= TRUE, # default FALSE\n",
        "\n",
        "  num_iterations= 1200, # default 100\n",
        "  learning_rate= 0.02, # default 0.1\n",
        "  feature_fraction= 0.5, # default 1\n",
        "  num_leaves= 750, # default 31\n",
        "  min_data_in_leaf= 5000 # default 20\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Yj-JV4yvOt"
      },
      "source": [
        "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
        "- si es un numero entero debe ir makeIntegerParam\n",
        "- si es un numero real (con decimales) debe ir makeNumericParam\n",
        "\n",
        "Es muy importante leer cuales son un lower y upper permitidos y además razonables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jENpR26ZyuS8",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
        "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
        "  makeNumericParam(\"min_sum_hessian_in_leaf\", lower= 0.001, upper= 0.1),\n",
        "  makeNumericParam(\"learning_rate\", lower= 0.005, upper= 0.1),\n",
        "  makeNumericParam(\"feature_fraction\", lower= 0.1, upper= 1.0),\n",
        "  makeNumericParam(\"bagging_fraction\", lower= 0.0, upper= 1.0),\n",
        "  makeNumericParam(\"lambda_l1\", lower= 0.0, upper= 10.0),\n",
        "  makeNumericParam(\"lambda_l2\", lower= 0.0, upper= 10.0),\n",
        "  makeNumericParam(\"min_gain_to_split\", lower= 0.0, upper= 15.0),\n",
        "  makeIntegerParam(\"bagging_freq\", lower= 1L, upper= 10L),\n",
        "  makeIntegerParam(\"num_iterations\", lower= 50L, upper= 3000L),\n",
        "  makeIntegerParam(\"max_depth\", lower= -1L, upper= 15),\n",
        "  makeIntegerParam(\"num_leaves\", lower= 2L, upper= 2048L),\n",
        "  makeIntegerParam(\"min_data_in_leaf\", lower= 1L, upper= 8000L)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_RPFUb3zMoW"
      },
      "source": [
        "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization: 30 es un valor muy tacaño, pero corre rápido deberia partir de 50, alcanzando los 100 si se dispone de tiempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q5Rd3pnbzSiG",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "or53-q3bmE5d",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# particionar agrega una columna llamada fold a un dataset\n",
        "#   que consiste en una particion estratificada segun agrupa\n",
        "# particionar( data=dataset, division=c(70,30),\n",
        "#  agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30\n",
        "\n",
        "particionar <- function(data, division, agrupa= \"\", campo= \"fold\", start= 1, seed= NA) {\n",
        "  if (!is.na(seed)) set.seed(seed, \"L'Ecuyer-CMRG\")\n",
        "\n",
        "  bloque <- unlist(mapply(\n",
        "    function(x, y) {rep(y, x)},division, seq(from= start, length.out= length(division))))\n",
        "\n",
        "  data[, (campo) := sample(rep(bloque,ceiling(.N / length(bloque))))[1:.N],by= agrupa]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CGKOZ9aMmKxi",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# iniciliazo el dataset de realidad, para medir ganancia\n",
        "realidad_inicializar <- function( pfuture, pparam) {\n",
        "\n",
        "  # datos para verificar la ganancia\n",
        "  drealidad <- pfuture[, list(numero_de_cliente, foto_mes, clase_ternaria)]\n",
        "\n",
        "  particionar(drealidad,\n",
        "    division= c(3, 7),\n",
        "    agrupa= \"clase_ternaria\",\n",
        "    seed= PARAM$semilla_kaggle\n",
        "  )\n",
        "\n",
        "  return( drealidad )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6aVLFlEbmM3s",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# evaluo ganancia en los datos de la realidad\n",
        "\n",
        "realidad_evaluar <- function( prealidad, pprediccion) {\n",
        "\n",
        "  prealidad[ pprediccion,\n",
        "    on= c(\"numero_de_cliente\", \"foto_mes\"),\n",
        "    predicted:= i.Predicted\n",
        "  ]\n",
        "\n",
        "  tbl <- prealidad[, list(\"qty\"=.N), list(fold, predicted, clase_ternaria)]\n",
        "\n",
        "  res <- list()\n",
        "  res$public  <- tbl[fold==1 & predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]/0.3\n",
        "  res$private <- tbl[fold==2 & predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]/0.7\n",
        "  res$total <- tbl[predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]\n",
        "\n",
        "  prealidad[, predicted:=NULL]\n",
        "  return( res )\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RWZXL1VZjMI"
      },
      "source": [
        "### 2.2.4  Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FM3lxKoLZ643",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"./competencia_01.csv.gz\", stringsAsFactors= TRUE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OsJ-91UeZ-I_",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "dataset_train <- dataset[foto_mes %in% PARAM$train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vrWE7BE0aB2J",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# paso la clase a binaria que tome valores {0,1}  enteros\n",
        "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
        "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
        "\n",
        "dataset_train[,\n",
        "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jP7YlQBnaW6W",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# defino los datos que forma parte del training\n",
        "# aqui se hace el undersampling de los CONTINUA\n",
        "# notar que para esto utilizo la SEGUNDA semilla\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "dataset_train[, azar := runif(nrow(dataset_train))]\n",
        "dataset_train[, training := 0L]\n",
        "\n",
        "dataset_train[\n",
        "  foto_mes %in%  PARAM$train &\n",
        "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
        "  training := 1L\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xElu4s5W4rX7",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# los campos que se van a utilizar\n",
        "\n",
        "campos_buenos <- setdiff(\n",
        "  colnames(dataset_train),\n",
        "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PppMHcGYaaol",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "82338"
            ],
            "text/latex": [
              "82338"
            ],
            "text/markdown": [
              "82338"
            ],
            "text/plain": [
              "[1] 82338"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "154"
            ],
            "text/latex": [
              "154"
            ],
            "text/markdown": [
              "154"
            ],
            "text/plain": [
              "[1] 154"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[training == 1L, clase01],\n",
        "  free_raw_data= FALSE\n",
        ")\n",
        "\n",
        "nrow(dtrain)\n",
        "ncol(dtrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta-EkOu3cphF"
      },
      "source": [
        "2.2.5 Configuracion Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cjgfurjdfiXb",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# En el argumento x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en cross validation del modelo entrenado\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  # x pisa (o agrega) a param_fijos\n",
        "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelocv <- lgb.cv(\n",
        "    data= dtrain,\n",
        "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
        "    stratified= TRUE,\n",
        "    param= param_completo\n",
        "  )\n",
        "\n",
        "  # obtengo la ganancia\n",
        "  AUC <- modelocv$best_score\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelocv)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
        "\n",
        "  return(AUC)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WLi_o1hocvN-",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Aqui comienza la configuracion de la Bayesian Optimization\n",
        "\n",
        "# en este archivo quedan la evolucion binaria de la BO\n",
        "kbayesiana <- \"bayesiana.RDATA\"\n",
        "\n",
        "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
        "\n",
        "configureMlr(show.learner.output= FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
        "  minimize= FALSE, # estoy Maximizando la ganancia\n",
        "  noisy= TRUE,\n",
        "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
        "  has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
        "  save.file.path= kbayesiana\n",
        ") # se graba cada 600 segundos\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "  ctrl,\n",
        "  iters= PARAM$hyperparametertuning$iteraciones\n",
        ") # cantidad de iteraciones\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales,\n",
        "# los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
        "\n",
        "# establezco la funcion que busca el maximo\n",
        "surr.km <- makeLearner(\n",
        "  \"regr.km\",\n",
        "  predict.type= \"se\",\n",
        "  covtype= \"matern3_2\",\n",
        "  control= list(trace= TRUE)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uUeVo5pc4zc"
      },
      "source": [
        "2.2.6 Corrida Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RcABNaKGciaz",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing y column(s) for design. Not provided.\n",
            "\n",
            "jue sept 11 16:01:50 2025 AUC 0.5\n",
            "\n",
            "jue sept 11 16:02:12 2025 AUC 0.885770632918326\n",
            "\n",
            "jue sept 11 16:02:28 2025 AUC 0.912988992287132\n",
            "\n",
            "jue sept 11 16:02:51 2025 AUC 0.909527715817772\n",
            "\n",
            "jue sept 11 16:03:05 2025 AUC 0.887065574982413\n",
            "\n",
            "jue sept 11 16:03:42 2025 AUC 0.911749570279686\n",
            "\n",
            "jue sept 11 16:04:00 2025 AUC 0.907235144706041\n",
            "\n",
            "jue sept 11 16:04:28 2025 AUC 0.907848487947552\n",
            "\n",
            "jue sept 11 16:04:56 2025 AUC 0.897368289793268\n",
            "\n",
            "jue sept 11 16:05:14 2025 AUC 0.915842438920888\n",
            "\n",
            "jue sept 11 16:05:41 2025 AUC 0.888629175674778\n",
            "\n",
            "jue sept 11 16:06:05 2025 AUC 0.892098898098057\n",
            "\n",
            "jue sept 11 16:06:06 2025 AUC 0.87058044490397\n",
            "\n",
            "jue sept 11 16:06:15 2025 AUC 0.90111223342467\n",
            "\n",
            "jue sept 11 16:06:34 2025 AUC 0.908090846102901\n",
            "\n",
            "jue sept 11 16:06:44 2025 AUC 0.892675977064306\n",
            "\n",
            "jue sept 11 16:07:13 2025 AUC 0.914829789372962\n",
            "\n",
            "jue sept 11 16:08:21 2025 AUC 0.915039182303603\n",
            "\n",
            "jue sept 11 16:08:25 2025 AUC 0.5\n",
            "\n",
            "jue sept 11 16:08:52 2025 AUC 0.910289576051487\n",
            "\n",
            "jue sept 11 16:09:23 2025 AUC 0.908525453170395\n",
            "\n",
            "jue sept 11 16:09:38 2025 AUC 0.909348175745685\n",
            "\n",
            "jue sept 11 16:09:45 2025 AUC 0.88754046264947\n",
            "\n",
            "jue sept 11 16:10:17 2025 AUC 0.920267489640283\n",
            "\n",
            "jue sept 11 16:10:52 2025 AUC 0.5\n",
            "\n",
            "jue sept 11 16:11:01 2025 AUC 0.903859433569891\n",
            "\n",
            "jue sept 11 16:11:13 2025 AUC 0.91067785963443\n",
            "\n",
            "jue sept 11 16:11:28 2025 AUC 0.891768166758521\n",
            "\n",
            "jue sept 11 16:11:31 2025 AUC 0.886676222873207\n",
            "\n",
            "jue sept 11 16:11:58 2025 AUC 0.914744596454986\n",
            "\n",
            "jue sept 11 16:12:32 2025 AUC 0.900192350350119\n",
            "\n",
            "jue sept 11 16:13:18 2025 AUC 0.912129869808294\n",
            "\n",
            "jue sept 11 16:13:23 2025 AUC 0.896384651316949\n",
            "\n",
            "jue sept 11 16:14:20 2025 AUC 0.911937200467595\n",
            "\n",
            "jue sept 11 16:14:22 2025 AUC 0.902020147136339\n",
            "\n",
            "jue sept 11 16:14:40 2025 AUC 0.913301651929427\n",
            "\n",
            "jue sept 11 16:14:58 2025 AUC 0.882445657883566\n",
            "\n",
            "jue sept 11 16:15:04 2025 AUC 0.890016374141768\n",
            "\n",
            "jue sept 11 16:15:46 2025 AUC 0.906387256733153\n",
            "\n",
            "jue sept 11 16:15:58 2025 AUC 0.5\n",
            "\n",
            "jue sept 11 16:16:05 2025 AUC 0.91045750970737\n",
            "\n",
            "jue sept 11 16:16:37 2025 AUC 0.909653142831022\n",
            "\n",
            "jue sept 11 16:16:50 2025 AUC 0.90971541542031\n",
            "\n",
            "jue sept 11 16:17:26 2025 AUC 0.922247492707528\n",
            "\n",
            "jue sept 11 16:17:51 2025 AUC 0.5\n",
            "\n",
            "jue sept 11 16:18:01 2025 AUC 0.879478584637012\n",
            "\n",
            "jue sept 11 16:18:07 2025 AUC 0.910952652055558\n",
            "\n",
            "jue sept 11 16:18:46 2025 AUC 0.906476213084777\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0353; learning_rate=0.0627; feature_fraction=0.684; bagging_fraction=0.0357; lambda_l1=3.05; lambda_l2=5.91; min_gain_to_split=3.27; bagging_freq=8; num_iterations=2341; max_depth=9; num_leaves=696; min_data_in_leaf=6014 : y = 0.5 : 21.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0635; learning_rate=0.0413; feature_fraction=0.399; bagging_fraction=0.446; lambda_l1=5.2; lambda_l2=2.31; min_gain_to_split=9.09; bagging_freq=8; num_iterations=1584; max_depth=8; num_leaves=546; min_data_in_leaf=7419 : y = 0.886 : 22.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0453; learning_rate=0.0382; feature_fraction=0.534; bagging_fraction=0.548; lambda_l1=2.56; lambda_l2=2.6; min_gain_to_split=9.02; bagging_freq=7; num_iterations=870; max_depth=8; num_leaves=1665; min_data_in_leaf=1676 : y = 0.913 : 16.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.062; learning_rate=0.046; feature_fraction=0.68; bagging_fraction=0.696; lambda_l1=6.38; lambda_l2=5.37; min_gain_to_split=4.96; bagging_freq=5; num_iterations=2205; max_depth=0; num_leaves=463; min_data_in_leaf=5828 : y = 0.91 : 22.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0247; learning_rate=0.0912; feature_fraction=0.721; bagging_fraction=0.23; lambda_l1=4.69; lambda_l2=0.982; min_gain_to_split=7.27; bagging_freq=5; num_iterations=1733; max_depth=4; num_leaves=1499; min_data_in_leaf=4473 : y = 0.887 : 14.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0214; learning_rate=0.0475; feature_fraction=0.51; bagging_fraction=0.811; lambda_l1=2.13; lambda_l2=4.18; min_gain_to_split=8.46; bagging_freq=3; num_iterations=1934; max_depth=6; num_leaves=970; min_data_in_leaf=5106 : y = 0.912 : 37.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0873; learning_rate=0.0536; feature_fraction=0.295; bagging_fraction=0.492; lambda_l1=7.72; lambda_l2=4.92; min_gain_to_split=10.6; bagging_freq=6; num_iterations=1207; max_depth=10; num_leaves=1632; min_data_in_leaf=3090 : y = 0.907 : 17.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0032; learning_rate=0.0325; feature_fraction=0.351; bagging_fraction=0.273; lambda_l1=5.31; lambda_l2=6.1; min_gain_to_split=6.35; bagging_freq=4; num_iterations=2310; max_depth=4; num_leaves=1017; min_data_in_leaf=1962 : y = 0.908 : 28.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0404; learning_rate=0.0947; feature_fraction=0.487; bagging_fraction=0.189; lambda_l1=8.76; lambda_l2=7.16; min_gain_to_split=12.5; bagging_freq=2; num_iterations=2680; max_depth=5; num_leaves=1252; min_data_in_leaf=2109 : y = 0.897 : 28.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0761; learning_rate=0.0647; feature_fraction=0.418; bagging_fraction=0.673; lambda_l1=6.21; lambda_l2=0.428; min_gain_to_split=6.09; bagging_freq=4; num_iterations=973; max_depth=5; num_leaves=1142; min_data_in_leaf=402 : y = 0.916 : 17.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0879; learning_rate=0.0576; feature_fraction=0.321; bagging_fraction=0.465; lambda_l1=2.9; lambda_l2=7.74; min_gain_to_split=11.8; bagging_freq=4; num_iterations=2067; max_depth=10; num_leaves=20; min_data_in_leaf=6505 : y = 0.889 : 27.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0797; learning_rate=0.0264; feature_fraction=0.933; bagging_fraction=0.354; lambda_l1=1.17; lambda_l2=3.45; min_gain_to_split=11; bagging_freq=6; num_iterations=2959; max_depth=6; num_leaves=1098; min_data_in_leaf=5309 : y = 0.892 : 23.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0329; learning_rate=0.0872; feature_fraction=0.576; bagging_fraction=0.115; lambda_l1=4.12; lambda_l2=4.77; min_gain_to_split=1.74; bagging_freq=9; num_iterations=121; max_depth=13; num_leaves=481; min_data_in_leaf=3318 : y = 0.871 : 1.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0317; learning_rate=0.00691; feature_fraction=0.707; bagging_fraction=0.319; lambda_l1=7.04; lambda_l2=9.06; min_gain_to_split=10.5; bagging_freq=9; num_iterations=934; max_depth=1; num_leaves=658; min_data_in_leaf=1092 : y = 0.901 : 9.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0664; learning_rate=0.0739; feature_fraction=0.165; bagging_fraction=0.661; lambda_l1=1.28; lambda_l2=8.69; min_gain_to_split=9.97; bagging_freq=6; num_iterations=1256; max_depth=12; num_leaves=1593; min_data_in_leaf=3979 : y = 0.908 : 18.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0904; learning_rate=0.0896; feature_fraction=0.567; bagging_fraction=0.169; lambda_l1=7.52; lambda_l2=5.07; min_gain_to_split=14.4; bagging_freq=6; num_iterations=1038; max_depth=8; num_leaves=302; min_data_in_leaf=2311 : y = 0.893 : 10.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0778; learning_rate=0.0763; feature_fraction=0.114; bagging_fraction=0.638; lambda_l1=4.48; lambda_l2=8.42; min_gain_to_split=5.74; bagging_freq=2; num_iterations=1773; max_depth=2; num_leaves=1779; min_data_in_leaf=44 : y = 0.915 : 29.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0545; learning_rate=0.0071; feature_fraction=0.59; bagging_fraction=0.771; lambda_l1=6.79; lambda_l2=5.77; min_gain_to_split=2.42; bagging_freq=2; num_iterations=2810; max_depth=13; num_leaves=1986; min_data_in_leaf=3525 : y = 0.915 : 68.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0582; learning_rate=0.0403; feature_fraction=0.125; bagging_fraction=0.0983; lambda_l1=8.35; lambda_l2=2.03; min_gain_to_split=1.93; bagging_freq=10; num_iterations=359; max_depth=2; num_leaves=865; min_data_in_leaf=4751 : y = 0.5 : 4.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0222; learning_rate=0.0147; feature_fraction=0.243; bagging_fraction=0.862; lambda_l1=9.96; lambda_l2=1.39; min_gain_to_split=8.2; bagging_freq=6; num_iterations=1427; max_depth=11; num_leaves=752; min_data_in_leaf=3492 : y = 0.91 : 26.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00602; learning_rate=0.0979; feature_fraction=0.624; bagging_fraction=0.926; lambda_l1=5.94; lambda_l2=1.11; min_gain_to_split=11.4; bagging_freq=4; num_iterations=2727; max_depth=9; num_leaves=133; min_data_in_leaf=6733 : y = 0.909 : 31.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0434; learning_rate=0.0701; feature_fraction=0.864; bagging_fraction=0.513; lambda_l1=2.36; lambda_l2=7.49; min_gain_to_split=10.1; bagging_freq=9; num_iterations=1845; max_depth=7; num_leaves=1953; min_data_in_leaf=3789 : y = 0.909 : 15.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0369; learning_rate=0.0153; feature_fraction=0.903; bagging_fraction=0.348; lambda_l1=3.67; lambda_l2=2.9; min_gain_to_split=4.46; bagging_freq=7; num_iterations=642; max_depth=1; num_leaves=1456; min_data_in_leaf=6349 : y = 0.888 : 6.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0486; learning_rate=0.0306; feature_fraction=0.738; bagging_fraction=0.394; lambda_l1=9.45; lambda_l2=5.52; min_gain_to_split=0.409; bagging_freq=5; num_iterations=1967; max_depth=-1; num_leaves=1824; min_data_in_leaf=995 : y = 0.92 : 32.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0735; learning_rate=0.0792; feature_fraction=0.191; bagging_fraction=0.132; lambda_l1=0.344; lambda_l2=6.87; min_gain_to_split=8.01; bagging_freq=7; num_iterations=2836; max_depth=1; num_leaves=604; min_data_in_leaf=7036 : y = 0.5 : 34.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0262; learning_rate=0.0245; feature_fraction=0.2; bagging_fraction=0.91; lambda_l1=0.901; lambda_l2=4.15; min_gain_to_split=13; bagging_freq=7; num_iterations=309; max_depth=7; num_leaves=1313; min_data_in_leaf=2613 : y = 0.904 : 9.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0729; learning_rate=0.086; feature_fraction=0.822; bagging_fraction=0.624; lambda_l1=3.13; lambda_l2=1.7; min_gain_to_split=9.64; bagging_freq=10; num_iterations=1141; max_depth=14; num_leaves=244; min_data_in_leaf=4253 : y = 0.911 : 12.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0597; learning_rate=0.0115; feature_fraction=0.146; bagging_fraction=0.149; lambda_l1=5.52; lambda_l2=6.93; min_gain_to_split=2.67; bagging_freq=1; num_iterations=828; max_depth=3; num_leaves=558; min_data_in_leaf=1245 : y = 0.892 : 15.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0694; learning_rate=0.0212; feature_fraction=0.791; bagging_fraction=0.398; lambda_l1=6.52; lambda_l2=3.62; min_gain_to_split=6.59; bagging_freq=3; num_iterations=177; max_depth=11; num_leaves=109; min_data_in_leaf=7287 : y = 0.887 : 3.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0111; learning_rate=0.0614; feature_fraction=0.875; bagging_fraction=0.6; lambda_l1=7.37; lambda_l2=3.09; min_gain_to_split=5.45; bagging_freq=5; num_iterations=2596; max_depth=13; num_leaves=290; min_data_in_leaf=688 : y = 0.915 : 27.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.055; learning_rate=0.00918; feature_fraction=0.645; bagging_fraction=0.71; lambda_l1=8.63; lambda_l2=4.4; min_gain_to_split=13.6; bagging_freq=10; num_iterations=2442; max_depth=4; num_leaves=1174; min_data_in_leaf=7873 : y = 0.9 : 33.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0993; learning_rate=0.0175; feature_fraction=0.457; bagging_fraction=0.984; lambda_l1=3.44; lambda_l2=9.99; min_gain_to_split=5.3; bagging_freq=1; num_iterations=1644; max_depth=15; num_leaves=823; min_data_in_leaf=6279 : y = 0.912 : 46.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0837; learning_rate=0.0551; feature_fraction=0.91; bagging_fraction=0.212; lambda_l1=0.727; lambda_l2=9.26; min_gain_to_split=11.9; bagging_freq=4; num_iterations=534; max_depth=0; num_leaves=175; min_data_in_leaf=2743 : y = 0.896 : 5.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0286; learning_rate=0.0841; feature_fraction=0.326; bagging_fraction=0.833; lambda_l1=4.96; lambda_l2=9.73; min_gain_to_split=3.79; bagging_freq=10; num_iterations=2570; max_depth=15; num_leaves=1366; min_data_in_leaf=5595 : y = 0.912 : 57.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0185; learning_rate=0.0275; feature_fraction=0.992; bagging_fraction=0.582; lambda_l1=9.02; lambda_l2=3.27; min_gain_to_split=3.5; bagging_freq=2; num_iterations=79; max_depth=-1; num_leaves=386; min_data_in_leaf=1583 : y = 0.902 : 2.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0935; learning_rate=0.0334; feature_fraction=0.81; bagging_fraction=0.734; lambda_l1=0.435; lambda_l2=0.0747; min_gain_to_split=7.69; bagging_freq=9; num_iterations=1359; max_depth=10; num_leaves=1899; min_data_in_leaf=4019 : y = 0.913 : 17.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00265; learning_rate=0.0744; feature_fraction=0.227; bagging_fraction=0.0734; lambda_l1=5.69; lambda_l2=6.61; min_gain_to_split=14.1; bagging_freq=10; num_iterations=1667; max_depth=6; num_leaves=1570; min_data_in_leaf=334 : y = 0.882 : 18.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0115; learning_rate=0.0991; feature_fraction=0.643; bagging_fraction=0.267; lambda_l1=1.5; lambda_l2=9.54; min_gain_to_split=0.073; bagging_freq=1; num_iterations=269; max_depth=14; num_leaves=1236; min_data_in_leaf=5907 : y = 0.89 : 5.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0482; learning_rate=0.0931; feature_fraction=0.273; bagging_fraction=0.956; lambda_l1=8.26; lambda_l2=3.85; min_gain_to_split=15; bagging_freq=2; num_iterations=2135; max_depth=15; num_leaves=1860; min_data_in_leaf=4878 : y = 0.906 : 41.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0961; learning_rate=0.081; feature_fraction=0.763; bagging_fraction=0.0503; lambda_l1=3.87; lambda_l2=1.53; min_gain_to_split=6.89; bagging_freq=1; num_iterations=1290; max_depth=11; num_leaves=1329; min_data_in_leaf=2880 : y = 0.5 : 12.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00826; learning_rate=0.0517; feature_fraction=0.948; bagging_fraction=0.966; lambda_l1=9.6; lambda_l2=2.16; min_gain_to_split=4.19; bagging_freq=9; num_iterations=477; max_depth=7; num_leaves=1717; min_data_in_leaf=7654 : y = 0.91 : 6.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.068; learning_rate=0.0442; feature_fraction=0.377; bagging_fraction=0.423; lambda_l1=1.94; lambda_l2=0.74; min_gain_to_split=13.3; bagging_freq=5; num_iterations=2482; max_depth=3; num_leaves=379; min_data_in_leaf=651 : y = 0.91 : 32.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0144; learning_rate=0.0709; feature_fraction=0.441; bagging_fraction=0.538; lambda_l1=4.17; lambda_l2=8.09; min_gain_to_split=1.27; bagging_freq=8; num_iterations=784; max_depth=1; num_leaves=61; min_data_in_leaf=4512 : y = 0.91 : 12.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0508; learning_rate=0.0205; feature_fraction=0.973; bagging_fraction=0.827; lambda_l1=0.0467; lambda_l2=8.13; min_gain_to_split=0.724; bagging_freq=2; num_iterations=1490; max_depth=3; num_leaves=1418; min_data_in_leaf=2349 : y = 0.922 : 36.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.083; learning_rate=0.0355; feature_fraction=0.529; bagging_fraction=0.0143; lambda_l1=7.96; lambda_l2=7.6; min_gain_to_split=0.964; bagging_freq=8; num_iterations=2882; max_depth=12; num_leaves=1035; min_data_in_leaf=5476 : y = 0.5 : 25.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0163; learning_rate=0.06; feature_fraction=0.42; bagging_fraction=0.302; lambda_l1=7.23; lambda_l2=6.34; min_gain_to_split=12.7; bagging_freq=3; num_iterations=716; max_depth=0; num_leaves=2019; min_data_in_leaf=6850 : y = 0.879 : 9.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0946; learning_rate=0.049; feature_fraction=0.849; bagging_fraction=0.886; lambda_l1=9.34; lambda_l2=8.8; min_gain_to_split=13.8; bagging_freq=8; num_iterations=579; max_depth=9; num_leaves=902; min_data_in_leaf=1415 : y = 0.911 : 6.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0388; learning_rate=0.0675; feature_fraction=0.254; bagging_fraction=0.77; lambda_l1=1.85; lambda_l2=0.375; min_gain_to_split=3.05; bagging_freq=3; num_iterations=2180; max_depth=14; num_leaves=811; min_data_in_leaf=7770 : y = 0.906 : 38.8 secs : initdesign\n",
            "\n",
            "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
            "\n",
            "jue sept 11 16:18:49 2025 AUC 0.900424221635234\n",
            "\n",
            "[mbo] 1: min_sum_hessian_in_leaf=0.0131; learning_rate=0.095; feature_fraction=0.578; bagging_fraction=0.174; lambda_l1=6.19; lambda_l2=8.39; min_gain_to_split=9.1; bagging_freq=7; num_iterations=89; max_depth=12; num_leaves=270; min_data_in_leaf=388 : y = 0.9 : 1.6 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:19:07 2025 AUC 0.90703516661278\n",
            "\n",
            "[mbo] 2: min_sum_hessian_in_leaf=0.0497; learning_rate=0.066; feature_fraction=0.716; bagging_fraction=0.243; lambda_l1=5.81; lambda_l2=2.92; min_gain_to_split=14.5; bagging_freq=1; num_iterations=1141; max_depth=8; num_leaves=448; min_data_in_leaf=1095 : y = 0.907 : 17.4 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:19:14 2025 AUC 0.910706702988733\n",
            "\n",
            "[mbo] 3: min_sum_hessian_in_leaf=0.0212; learning_rate=0.0942; feature_fraction=0.698; bagging_fraction=0.228; lambda_l1=2.88; lambda_l2=4.41; min_gain_to_split=1.07; bagging_freq=9; num_iterations=531; max_depth=14; num_leaves=1550; min_data_in_leaf=2161 : y = 0.911 : 6.8 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:19:39 2025 AUC 0.906132118368531\n",
            "\n",
            "[mbo] 4: min_sum_hessian_in_leaf=0.00833; learning_rate=0.0889; feature_fraction=0.518; bagging_fraction=0.262; lambda_l1=4.06; lambda_l2=7.87; min_gain_to_split=10.3; bagging_freq=4; num_iterations=2149; max_depth=6; num_leaves=1619; min_data_in_leaf=335 : y = 0.906 : 24.4 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:19:48 2025 AUC 0.905502011796381\n",
            "\n",
            "[mbo] 5: min_sum_hessian_in_leaf=0.0377; learning_rate=0.0974; feature_fraction=0.731; bagging_fraction=0.358; lambda_l1=4.56; lambda_l2=7.17; min_gain_to_split=6.37; bagging_freq=6; num_iterations=1005; max_depth=12; num_leaves=448; min_data_in_leaf=3227 : y = 0.906 : 8.2 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:20:05 2025 AUC 0.912694941412305\n",
            "\n",
            "[mbo] 6: min_sum_hessian_in_leaf=0.0762; learning_rate=0.0447; feature_fraction=0.862; bagging_fraction=0.893; lambda_l1=6.68; lambda_l2=6.69; min_gain_to_split=5.85; bagging_freq=6; num_iterations=1515; max_depth=10; num_leaves=1382; min_data_in_leaf=5970 : y = 0.913 : 16.1 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:20:12 2025 AUC 0.898901812917516\n",
            "\n",
            "[mbo] 7: min_sum_hessian_in_leaf=0.0308; learning_rate=0.0206; feature_fraction=0.511; bagging_fraction=0.19; lambda_l1=4.52; lambda_l2=7.4; min_gain_to_split=0.069; bagging_freq=2; num_iterations=357; max_depth=15; num_leaves=164; min_data_in_leaf=1937 : y = 0.899 : 6.1 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:20:56 2025 AUC 0.913494726029721\n",
            "\n",
            "[mbo] 8: min_sum_hessian_in_leaf=0.0383; learning_rate=0.0178; feature_fraction=0.692; bagging_fraction=0.426; lambda_l1=6.75; lambda_l2=5.28; min_gain_to_split=6.51; bagging_freq=1; num_iterations=2315; max_depth=4; num_leaves=1149; min_data_in_leaf=1120 : y = 0.913 : 43.6 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:21:33 2025 AUC 0.917902185698847\n",
            "\n",
            "[mbo] 9: min_sum_hessian_in_leaf=0.0595; learning_rate=0.0526; feature_fraction=0.547; bagging_fraction=0.762; lambda_l1=3.75; lambda_l2=7.69; min_gain_to_split=3.74; bagging_freq=9; num_iterations=2086; max_depth=10; num_leaves=874; min_data_in_leaf=830 : y = 0.918 : 35.4 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:22:00 2025 AUC 0.919262325653536\n",
            "\n",
            "[mbo] 10: min_sum_hessian_in_leaf=0.0557; learning_rate=0.0477; feature_fraction=0.849; bagging_fraction=0.603; lambda_l1=6.22; lambda_l2=3.91; min_gain_to_split=1.71; bagging_freq=6; num_iterations=2434; max_depth=5; num_leaves=1263; min_data_in_leaf=2936 : y = 0.919 : 27.0 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:22:22 2025 AUC 0.903152829570607\n",
            "\n",
            "[mbo] 11: min_sum_hessian_in_leaf=0.0215; learning_rate=0.0846; feature_fraction=0.807; bagging_fraction=0.345; lambda_l1=8.61; lambda_l2=4.74; min_gain_to_split=14.5; bagging_freq=6; num_iterations=2721; max_depth=6; num_leaves=1490; min_data_in_leaf=3163 : y = 0.903 : 20.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:22:45 2025 AUC 0.915020891305346\n",
            "\n",
            "[mbo] 12: min_sum_hessian_in_leaf=0.0542; learning_rate=0.0804; feature_fraction=0.652; bagging_fraction=0.777; lambda_l1=4.96; lambda_l2=3.59; min_gain_to_split=5.32; bagging_freq=7; num_iterations=2427; max_depth=3; num_leaves=1638; min_data_in_leaf=2033 : y = 0.915 : 22.7 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:22:58 2025 AUC 0.892123403044922\n",
            "\n",
            "[mbo] 13: min_sum_hessian_in_leaf=0.0862; learning_rate=0.00796; feature_fraction=0.184; bagging_fraction=0.214; lambda_l1=6.09; lambda_l2=7.88; min_gain_to_split=13.3; bagging_freq=1; num_iterations=680; max_depth=4; num_leaves=568; min_data_in_leaf=36 : y = 0.892 : 11.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:23:14 2025 AUC 0.915418422509439\n",
            "\n",
            "[mbo] 14: min_sum_hessian_in_leaf=0.0731; learning_rate=0.0637; feature_fraction=0.923; bagging_fraction=0.541; lambda_l1=4.49; lambda_l2=8.99; min_gain_to_split=7.57; bagging_freq=6; num_iterations=1874; max_depth=4; num_leaves=605; min_data_in_leaf=62 : y = 0.915 : 15.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:23:33 2025 AUC 0.916014920478129\n",
            "\n",
            "[mbo] 15: min_sum_hessian_in_leaf=0.0344; learning_rate=0.0492; feature_fraction=0.717; bagging_fraction=0.953; lambda_l1=5.91; lambda_l2=9.89; min_gain_to_split=3.28; bagging_freq=6; num_iterations=1757; max_depth=8; num_leaves=699; min_data_in_leaf=2186 : y = 0.916 : 18.7 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:23:39 2025 AUC 0.894200887544584\n",
            "\n",
            "[mbo] 16: min_sum_hessian_in_leaf=0.0176; learning_rate=0.0941; feature_fraction=0.749; bagging_fraction=0.217; lambda_l1=6.85; lambda_l2=6.11; min_gain_to_split=12.5; bagging_freq=6; num_iterations=569; max_depth=3; num_leaves=238; min_data_in_leaf=2723 : y = 0.894 : 4.3 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:23:53 2025 AUC 0.897094296100896\n",
            "\n",
            "[mbo] 17: min_sum_hessian_in_leaf=0.0209; learning_rate=0.0896; feature_fraction=0.276; bagging_fraction=0.182; lambda_l1=3.89; lambda_l2=7.98; min_gain_to_split=14.9; bagging_freq=5; num_iterations=1461; max_depth=1; num_leaves=452; min_data_in_leaf=368 : y = 0.897 : 13.7 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:24:08 2025 AUC 0.915377961231749\n",
            "\n",
            "[mbo] 18: min_sum_hessian_in_leaf=0.0397; learning_rate=0.05; feature_fraction=0.803; bagging_fraction=0.708; lambda_l1=6.54; lambda_l2=8.12; min_gain_to_split=5.29; bagging_freq=4; num_iterations=1429; max_depth=9; num_leaves=950; min_data_in_leaf=2299 : y = 0.915 : 14.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:24:31 2025 AUC 0.915137534679265\n",
            "\n",
            "[mbo] 19: min_sum_hessian_in_leaf=0.0667; learning_rate=0.086; feature_fraction=0.934; bagging_fraction=0.297; lambda_l1=5.69; lambda_l2=6.84; min_gain_to_split=0.957; bagging_freq=2; num_iterations=1468; max_depth=1; num_leaves=1469; min_data_in_leaf=1834 : y = 0.915 : 21.4 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:24:34 2025 AUC 0.902673598775061\n",
            "\n",
            "[mbo] 20: min_sum_hessian_in_leaf=0.00204; learning_rate=0.0911; feature_fraction=0.562; bagging_fraction=0.132; lambda_l1=3.98; lambda_l2=8.64; min_gain_to_split=5.9; bagging_freq=9; num_iterations=200; max_depth=15; num_leaves=1781; min_data_in_leaf=137 : y = 0.903 : 2.8 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:25:02 2025 AUC 0.919625835276366\n",
            "\n",
            "[mbo] 21: min_sum_hessian_in_leaf=0.0516; learning_rate=0.0341; feature_fraction=0.36; bagging_fraction=0.535; lambda_l1=3.31; lambda_l2=4.07; min_gain_to_split=0.272; bagging_freq=5; num_iterations=1048; max_depth=14; num_leaves=523; min_data_in_leaf=2071 : y = 0.92 : 26.7 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:25:22 2025 AUC 0.911021064989623\n",
            "\n",
            "[mbo] 22: min_sum_hessian_in_leaf=0.00135; learning_rate=0.0774; feature_fraction=0.771; bagging_fraction=0.359; lambda_l1=4.05; lambda_l2=0.258; min_gain_to_split=7.2; bagging_freq=5; num_iterations=1890; max_depth=2; num_leaves=1744; min_data_in_leaf=2040 : y = 0.911 : 19.1 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:25:38 2025 AUC 0.916695327920497\n",
            "\n",
            "[mbo] 23: min_sum_hessian_in_leaf=0.0548; learning_rate=0.079; feature_fraction=0.811; bagging_fraction=0.936; lambda_l1=2.29; lambda_l2=1.63; min_gain_to_split=4.79; bagging_freq=2; num_iterations=879; max_depth=15; num_leaves=757; min_data_in_leaf=3570 : y = 0.917 : 15.2 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:26:02 2025 AUC 0.917823635476125\n",
            "\n",
            "[mbo] 24: min_sum_hessian_in_leaf=0.0953; learning_rate=0.0771; feature_fraction=0.584; bagging_fraction=0.823; lambda_l1=3.44; lambda_l2=6.66; min_gain_to_split=3.47; bagging_freq=1; num_iterations=1028; max_depth=12; num_leaves=742; min_data_in_leaf=2264 : y = 0.918 : 22.6 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:26:43 2025 AUC 0.917356787826865\n",
            "\n",
            "[mbo] 25: min_sum_hessian_in_leaf=0.0714; learning_rate=0.0171; feature_fraction=0.711; bagging_fraction=0.853; lambda_l1=2.18; lambda_l2=4.33; min_gain_to_split=3.75; bagging_freq=7; num_iterations=2368; max_depth=15; num_leaves=1044; min_data_in_leaf=2852 : y = 0.917 : 39.4 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:27:00 2025 AUC 0.917082027966037\n",
            "\n",
            "[mbo] 26: min_sum_hessian_in_leaf=0.0494; learning_rate=0.0193; feature_fraction=0.639; bagging_fraction=0.812; lambda_l1=4.75; lambda_l2=6.86; min_gain_to_split=1.09; bagging_freq=8; num_iterations=642; max_depth=13; num_leaves=1691; min_data_in_leaf=2567 : y = 0.917 : 16.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:27:33 2025 AUC 0.917966239959121\n",
            "\n",
            "[mbo] 27: min_sum_hessian_in_leaf=0.0714; learning_rate=0.0631; feature_fraction=0.606; bagging_fraction=0.591; lambda_l1=1.08; lambda_l2=2.56; min_gain_to_split=5.31; bagging_freq=2; num_iterations=1697; max_depth=2; num_leaves=283; min_data_in_leaf=1675 : y = 0.918 : 31.9 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:28:15 2025 AUC 0.91529975206427\n",
            "\n",
            "[mbo] 28: min_sum_hessian_in_leaf=0.0741; learning_rate=0.0122; feature_fraction=0.51; bagging_fraction=0.608; lambda_l1=7.51; lambda_l2=6.38; min_gain_to_split=2.36; bagging_freq=8; num_iterations=1571; max_depth=5; num_leaves=855; min_data_in_leaf=1126 : y = 0.915 : 40.0 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:28:39 2025 AUC 0.915169490140453\n",
            "\n",
            "[mbo] 29: min_sum_hessian_in_leaf=0.0691; learning_rate=0.0128; feature_fraction=0.986; bagging_fraction=0.428; lambda_l1=2.32; lambda_l2=7.53; min_gain_to_split=1.81; bagging_freq=4; num_iterations=1351; max_depth=-1; num_leaves=509; min_data_in_leaf=2566 : y = 0.915 : 23.8 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:29:23 2025 AUC 0.915377157207229\n",
            "\n",
            "[mbo] 30: min_sum_hessian_in_leaf=0.0524; learning_rate=0.0555; feature_fraction=0.543; bagging_fraction=0.871; lambda_l1=4.47; lambda_l2=9.48; min_gain_to_split=7.07; bagging_freq=1; num_iterations=1659; max_depth=13; num_leaves=1562; min_data_in_leaf=1030 : y = 0.915 : 42.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 31 in the file bayesiana.RDATA.\n",
            "\n",
            "jue sept 11 16:29:37 2025 AUC 0.911577503983228\n",
            "\n",
            "[mbo] 31: min_sum_hessian_in_leaf=0.0965; learning_rate=0.0725; feature_fraction=0.795; bagging_fraction=0.357; lambda_l1=9.71; lambda_l2=6.3; min_gain_to_split=3.48; bagging_freq=4; num_iterations=1275; max_depth=1; num_leaves=233; min_data_in_leaf=612 : y = 0.912 : 13.2 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:30:04 2025 AUC 0.909245109317492\n",
            "\n",
            "[mbo] 32: min_sum_hessian_in_leaf=0.0187; learning_rate=0.0724; feature_fraction=0.772; bagging_fraction=0.421; lambda_l1=4.17; lambda_l2=2.02; min_gain_to_split=2.24; bagging_freq=2; num_iterations=1783; max_depth=10; num_leaves=1645; min_data_in_leaf=4805 : y = 0.909 : 26.1 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:30:45 2025 AUC 0.908475393519697\n",
            "\n",
            "[mbo] 33: min_sum_hessian_in_leaf=0.0382; learning_rate=0.0186; feature_fraction=0.525; bagging_fraction=0.55; lambda_l1=5.4; lambda_l2=0.965; min_gain_to_split=12.3; bagging_freq=5; num_iterations=2546; max_depth=8; num_leaves=511; min_data_in_leaf=4046 : y = 0.908 : 39.9 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:30:56 2025 AUC 0.907593743000281\n",
            "\n",
            "[mbo] 34: min_sum_hessian_in_leaf=0.0415; learning_rate=0.0563; feature_fraction=0.334; bagging_fraction=0.951; lambda_l1=7.71; lambda_l2=8.26; min_gain_to_split=6.53; bagging_freq=2; num_iterations=379; max_depth=7; num_leaves=220; min_data_in_leaf=6897 : y = 0.908 : 9.3 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:31:22 2025 AUC 0.915078444438531\n",
            "\n",
            "[mbo] 35: min_sum_hessian_in_leaf=0.022; learning_rate=0.0566; feature_fraction=0.313; bagging_fraction=0.25; lambda_l1=6.63; lambda_l2=5.36; min_gain_to_split=0.64; bagging_freq=1; num_iterations=1440; max_depth=1; num_leaves=1293; min_data_in_leaf=69 : y = 0.915 : 25.2 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:32:16 2025 AUC 0.917883908460512\n",
            "\n",
            "[mbo] 36: min_sum_hessian_in_leaf=0.0182; learning_rate=0.0199; feature_fraction=0.402; bagging_fraction=0.954; lambda_l1=3.52; lambda_l2=3.77; min_gain_to_split=0.32; bagging_freq=4; num_iterations=1862; max_depth=14; num_leaves=1351; min_data_in_leaf=6553 : y = 0.918 : 52.9 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:32:45 2025 AUC 0.91293246457083\n",
            "\n",
            "[mbo] 37: min_sum_hessian_in_leaf=0.0523; learning_rate=0.0723; feature_fraction=0.374; bagging_fraction=0.967; lambda_l1=2.87; lambda_l2=2.62; min_gain_to_split=4.99; bagging_freq=10; num_iterations=1442; max_depth=6; num_leaves=862; min_data_in_leaf=5588 : y = 0.913 : 27.3 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:33:07 2025 AUC 0.919887625297251\n",
            "\n",
            "[mbo] 38: min_sum_hessian_in_leaf=0.0503; learning_rate=0.0237; feature_fraction=0.573; bagging_fraction=0.775; lambda_l1=2.26; lambda_l2=3.88; min_gain_to_split=0.725; bagging_freq=6; num_iterations=761; max_depth=6; num_leaves=238; min_data_in_leaf=1683 : y = 0.92 : 20.8 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:33:42 2025 AUC 0.919031264531257\n",
            "\n",
            "[mbo] 39: min_sum_hessian_in_leaf=0.0611; learning_rate=0.0179; feature_fraction=0.719; bagging_fraction=0.67; lambda_l1=5.29; lambda_l2=4.17; min_gain_to_split=0.0781; bagging_freq=3; num_iterations=1491; max_depth=0; num_leaves=1823; min_data_in_leaf=3353 : y = 0.919 : 34.2 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:34:10 2025 AUC 0.91965553754317\n",
            "\n",
            "[mbo] 40: min_sum_hessian_in_leaf=0.0153; learning_rate=0.0715; feature_fraction=0.553; bagging_fraction=0.864; lambda_l1=2.74; lambda_l2=7.21; min_gain_to_split=0.555; bagging_freq=9; num_iterations=1144; max_depth=14; num_leaves=370; min_data_in_leaf=4882 : y = 0.92 : 26.9 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:34:52 2025 AUC 0.922612078862226\n",
            "\n",
            "[mbo] 41: min_sum_hessian_in_leaf=0.0433; learning_rate=0.0779; feature_fraction=0.444; bagging_fraction=0.503; lambda_l1=4.18; lambda_l2=2.26; min_gain_to_split=0.879; bagging_freq=6; num_iterations=2260; max_depth=-1; num_leaves=958; min_data_in_leaf=915 : y = 0.923 : 40.2 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:34:58 2025 AUC 0.914524294932724\n",
            "\n",
            "[mbo] 42: min_sum_hessian_in_leaf=0.058; learning_rate=0.0903; feature_fraction=0.921; bagging_fraction=0.236; lambda_l1=1.54; lambda_l2=0.805; min_gain_to_split=0.249; bagging_freq=10; num_iterations=361; max_depth=10; num_leaves=280; min_data_in_leaf=1809 : y = 0.915 : 5.4 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:35:18 2025 AUC 0.905046780046716\n",
            "\n",
            "[mbo] 43: min_sum_hessian_in_leaf=0.043; learning_rate=0.0759; feature_fraction=0.539; bagging_fraction=0.244; lambda_l1=9.59; lambda_l2=5.28; min_gain_to_split=6.4; bagging_freq=10; num_iterations=1770; max_depth=5; num_leaves=1566; min_data_in_leaf=1018 : y = 0.905 : 18.7 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:36:14 2025 AUC 0.921508739988622\n",
            "\n",
            "[mbo] 44: min_sum_hessian_in_leaf=0.0129; learning_rate=0.0292; feature_fraction=0.471; bagging_fraction=0.673; lambda_l1=1.83; lambda_l2=1.15; min_gain_to_split=0.13; bagging_freq=9; num_iterations=2081; max_depth=11; num_leaves=1210; min_data_in_leaf=3488 : y = 0.922 : 54.6 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:36:16 2025 AUC 0.90290238315794\n",
            "\n",
            "[mbo] 45: min_sum_hessian_in_leaf=0.0277; learning_rate=0.0942; feature_fraction=0.686; bagging_fraction=0.146; lambda_l1=2.54; lambda_l2=7.12; min_gain_to_split=1.68; bagging_freq=10; num_iterations=70; max_depth=10; num_leaves=356; min_data_in_leaf=1179 : y = 0.903 : 1.2 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:36:26 2025 AUC 0.905141984568282\n",
            "\n",
            "[mbo] 46: min_sum_hessian_in_leaf=0.0949; learning_rate=0.0967; feature_fraction=0.963; bagging_fraction=0.304; lambda_l1=4.51; lambda_l2=0.535; min_gain_to_split=14.2; bagging_freq=7; num_iterations=1115; max_depth=8; num_leaves=47; min_data_in_leaf=1793 : y = 0.905 : 8.2 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:37:11 2025 AUC 0.921628745076092\n",
            "\n",
            "[mbo] 47: min_sum_hessian_in_leaf=0.0708; learning_rate=0.0765; feature_fraction=0.971; bagging_fraction=0.465; lambda_l1=1.5; lambda_l2=0.302; min_gain_to_split=0.485; bagging_freq=9; num_iterations=1900; max_depth=13; num_leaves=1204; min_data_in_leaf=80 : y = 0.922 : 44.1 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:37:29 2025 AUC 0.900507161816986\n",
            "\n",
            "[mbo] 48: min_sum_hessian_in_leaf=0.00879; learning_rate=0.0468; feature_fraction=0.626; bagging_fraction=0.191; lambda_l1=9.84; lambda_l2=9.03; min_gain_to_split=14.6; bagging_freq=3; num_iterations=1778; max_depth=5; num_leaves=1617; min_data_in_leaf=617 : y = 0.901 : 16.9 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:38:17 2025 AUC 0.915749715620706\n",
            "\n",
            "[mbo] 49: min_sum_hessian_in_leaf=0.0852; learning_rate=0.0295; feature_fraction=0.587; bagging_fraction=0.665; lambda_l1=2.26; lambda_l2=1.83; min_gain_to_split=7.06; bagging_freq=5; num_iterations=2462; max_depth=13; num_leaves=1088; min_data_in_leaf=1289 : y = 0.916 : 46.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:38:53 2025 AUC 0.918601031609148\n",
            "\n",
            "[mbo] 50: min_sum_hessian_in_leaf=0.073; learning_rate=0.034; feature_fraction=0.251; bagging_fraction=0.904; lambda_l1=3.21; lambda_l2=8.11; min_gain_to_split=0.505; bagging_freq=3; num_iterations=1061; max_depth=4; num_leaves=1174; min_data_in_leaf=3133 : y = 0.919 : 34.7 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:39:15 2025 AUC 0.917192620559915\n",
            "\n",
            "[mbo] 51: min_sum_hessian_in_leaf=0.0454; learning_rate=0.0491; feature_fraction=0.802; bagging_fraction=0.5; lambda_l1=7.21; lambda_l2=0.422; min_gain_to_split=2.81; bagging_freq=10; num_iterations=1791; max_depth=11; num_leaves=15; min_data_in_leaf=1476 : y = 0.917 : 19.9 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:40:11 2025 AUC 0.922360206334752\n",
            "\n",
            "[mbo] 52: min_sum_hessian_in_leaf=0.00376; learning_rate=0.028; feature_fraction=0.735; bagging_fraction=0.506; lambda_l1=1.48; lambda_l2=3.65; min_gain_to_split=0.831; bagging_freq=10; num_iterations=2977; max_depth=9; num_leaves=901; min_data_in_leaf=1021 : y = 0.922 : 54.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 53 in the file bayesiana.RDATA.\n",
            "\n",
            "jue sept 11 16:40:44 2025 AUC 0.922297940322955\n",
            "\n",
            "[mbo] 53: min_sum_hessian_in_leaf=0.0534; learning_rate=0.0286; feature_fraction=0.889; bagging_fraction=0.483; lambda_l1=2.95; lambda_l2=2.65; min_gain_to_split=0.562; bagging_freq=5; num_iterations=1400; max_depth=4; num_leaves=1104; min_data_in_leaf=564 : y = 0.922 : 31.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:41:54 2025 AUC 0.921166670438419\n",
            "\n",
            "[mbo] 54: min_sum_hessian_in_leaf=0.0233; learning_rate=0.0999; feature_fraction=0.565; bagging_fraction=0.574; lambda_l1=0.96; lambda_l2=3.68; min_gain_to_split=0.00355; bagging_freq=10; num_iterations=1822; max_depth=11; num_leaves=675; min_data_in_leaf=1514 : y = 0.921 : 69.3 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:42:50 2025 AUC 0.920561475092913\n",
            "\n",
            "[mbo] 55: min_sum_hessian_in_leaf=0.0657; learning_rate=0.0264; feature_fraction=0.324; bagging_fraction=0.487; lambda_l1=1.11; lambda_l2=2.36; min_gain_to_split=2.95; bagging_freq=7; num_iterations=2943; max_depth=7; num_leaves=1752; min_data_in_leaf=972 : y = 0.921 : 54.3 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:43:31 2025 AUC 0.915765948912594\n",
            "\n",
            "[mbo] 56: min_sum_hessian_in_leaf=0.00187; learning_rate=0.0251; feature_fraction=0.139; bagging_fraction=0.57; lambda_l1=4.13; lambda_l2=8.32; min_gain_to_split=1.57; bagging_freq=4; num_iterations=2215; max_depth=3; num_leaves=1776; min_data_in_leaf=1529 : y = 0.916 : 39.2 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:44:12 2025 AUC 0.916586806526193\n",
            "\n",
            "[mbo] 57: min_sum_hessian_in_leaf=0.0813; learning_rate=0.0188; feature_fraction=0.174; bagging_fraction=0.739; lambda_l1=1.32; lambda_l2=4.62; min_gain_to_split=1.83; bagging_freq=3; num_iterations=1793; max_depth=4; num_leaves=1509; min_data_in_leaf=2143 : y = 0.917 : 39.8 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:44:41 2025 AUC 0.916767766942666\n",
            "\n",
            "[mbo] 58: min_sum_hessian_in_leaf=0.0585; learning_rate=0.0188; feature_fraction=0.453; bagging_fraction=0.288; lambda_l1=4.91; lambda_l2=8.15; min_gain_to_split=0.185; bagging_freq=1; num_iterations=1308; max_depth=2; num_leaves=457; min_data_in_leaf=731 : y = 0.917 : 27.4 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:44:53 2025 AUC 0.920018445576559\n",
            "\n",
            "[mbo] 59: min_sum_hessian_in_leaf=0.088; learning_rate=0.0855; feature_fraction=0.9; bagging_fraction=0.569; lambda_l1=1.24; lambda_l2=7.54; min_gain_to_split=0.39; bagging_freq=4; num_iterations=595; max_depth=2; num_leaves=1297; min_data_in_leaf=2691 : y = 0.92 : 10.1 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:45:05 2025 AUC 0.916634240468172\n",
            "\n",
            "[mbo] 60: min_sum_hessian_in_leaf=0.0187; learning_rate=0.0748; feature_fraction=0.839; bagging_fraction=0.855; lambda_l1=6.86; lambda_l2=1.7; min_gain_to_split=1.02; bagging_freq=5; num_iterations=776; max_depth=1; num_leaves=1462; min_data_in_leaf=2886 : y = 0.917 : 11.1 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:45:36 2025 AUC 0.921530277528457\n",
            "\n",
            "[mbo] 61: min_sum_hessian_in_leaf=0.00985; learning_rate=0.0908; feature_fraction=0.464; bagging_fraction=0.405; lambda_l1=2; lambda_l2=7.21; min_gain_to_split=0.272; bagging_freq=8; num_iterations=1376; max_depth=3; num_leaves=1302; min_data_in_leaf=1319 : y = 0.922 : 29.8 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:46:10 2025 AUC 0.91851950325641\n",
            "\n",
            "[mbo] 62: min_sum_hessian_in_leaf=0.00252; learning_rate=0.0283; feature_fraction=0.335; bagging_fraction=0.453; lambda_l1=4.83; lambda_l2=4.25; min_gain_to_split=2.01; bagging_freq=9; num_iterations=1877; max_depth=6; num_leaves=1374; min_data_in_leaf=718 : y = 0.919 : 32.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:46:33 2025 AUC 0.920640658204834\n",
            "\n",
            "[mbo] 63: min_sum_hessian_in_leaf=0.0806; learning_rate=0.0551; feature_fraction=0.645; bagging_fraction=0.416; lambda_l1=3.42; lambda_l2=4.39; min_gain_to_split=0.758; bagging_freq=9; num_iterations=1337; max_depth=5; num_leaves=1061; min_data_in_leaf=1418 : y = 0.921 : 21.4 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:46:55 2025 AUC 0.909852223625197\n",
            "\n",
            "[mbo] 64: min_sum_hessian_in_leaf=0.0477; learning_rate=0.0239; feature_fraction=0.899; bagging_fraction=0.468; lambda_l1=0.633; lambda_l2=3.42; min_gain_to_split=8.84; bagging_freq=8; num_iterations=2129; max_depth=0; num_leaves=1359; min_data_in_leaf=3577 : y = 0.91 : 20.4 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:47:43 2025 AUC 0.914432089401394\n",
            "\n",
            "[mbo] 65: min_sum_hessian_in_leaf=0.057; learning_rate=0.0419; feature_fraction=0.27; bagging_fraction=0.908; lambda_l1=4.4; lambda_l2=6.7; min_gain_to_split=3.71; bagging_freq=2; num_iterations=2255; max_depth=14; num_leaves=233; min_data_in_leaf=4554 : y = 0.914 : 46.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:48:25 2025 AUC 0.922218476857881\n",
            "\n",
            "[mbo] 66: min_sum_hessian_in_leaf=0.0781; learning_rate=0.0759; feature_fraction=0.458; bagging_fraction=0.475; lambda_l1=2.99; lambda_l2=9.96; min_gain_to_split=0.024; bagging_freq=4; num_iterations=1386; max_depth=0; num_leaves=1883; min_data_in_leaf=1001 : y = 0.922 : 41.0 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:48:34 2025 AUC 0.914255712185002\n",
            "\n",
            "[mbo] 67: min_sum_hessian_in_leaf=0.0399; learning_rate=0.0461; feature_fraction=0.978; bagging_fraction=0.732; lambda_l1=0.754; lambda_l2=2.16; min_gain_to_split=0.66; bagging_freq=8; num_iterations=318; max_depth=6; num_leaves=860; min_data_in_leaf=5658 : y = 0.914 : 7.0 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:48:37 2025 AUC 0.888566220601379\n",
            "\n",
            "[mbo] 68: min_sum_hessian_in_leaf=0.077; learning_rate=0.0942; feature_fraction=0.548; bagging_fraction=0.228; lambda_l1=1.46; lambda_l2=6.5; min_gain_to_split=7; bagging_freq=10; num_iterations=95; max_depth=14; num_leaves=28; min_data_in_leaf=3179 : y = 0.889 : 1.6 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:49:13 2025 AUC 0.92163949144675\n",
            "\n",
            "[mbo] 69: min_sum_hessian_in_leaf=0.0516; learning_rate=0.0926; feature_fraction=0.543; bagging_fraction=0.477; lambda_l1=1.48; lambda_l2=5.16; min_gain_to_split=0.76; bagging_freq=5; num_iterations=1609; max_depth=7; num_leaves=976; min_data_in_leaf=1336 : y = 0.922 : 33.7 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:50:19 2025 AUC 0.923530345820781\n",
            "\n",
            "[mbo] 70: min_sum_hessian_in_leaf=0.0775; learning_rate=0.0724; feature_fraction=0.773; bagging_fraction=0.55; lambda_l1=3.31; lambda_l2=4.68; min_gain_to_split=0.0399; bagging_freq=9; num_iterations=2233; max_depth=6; num_leaves=1699; min_data_in_leaf=392 : y = 0.924 : 64.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 71 in the file bayesiana.RDATA.\n",
            "\n",
            "jue sept 11 16:50:36 2025 AUC 0.913427335803406\n",
            "\n",
            "[mbo] 71: min_sum_hessian_in_leaf=0.086; learning_rate=0.0176; feature_fraction=0.682; bagging_fraction=0.974; lambda_l1=7.28; lambda_l2=2.13; min_gain_to_split=8.78; bagging_freq=1; num_iterations=1126; max_depth=3; num_leaves=1508; min_data_in_leaf=1412 : y = 0.913 : 14.7 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:50:39 2025 AUC 0.906562817478422\n",
            "\n",
            "[mbo] 72: min_sum_hessian_in_leaf=0.0376; learning_rate=0.0977; feature_fraction=0.854; bagging_fraction=0.307; lambda_l1=0.637; lambda_l2=0.544; min_gain_to_split=1.16; bagging_freq=5; num_iterations=68; max_depth=10; num_leaves=747; min_data_in_leaf=2721 : y = 0.907 : 1.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:50:52 2025 AUC 0.919326161573659\n",
            "\n",
            "[mbo] 73: min_sum_hessian_in_leaf=0.00861; learning_rate=0.0781; feature_fraction=0.664; bagging_fraction=0.645; lambda_l1=0.929; lambda_l2=8.79; min_gain_to_split=0.00893; bagging_freq=8; num_iterations=918; max_depth=1; num_leaves=1859; min_data_in_leaf=1084 : y = 0.919 : 11.9 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:51:27 2025 AUC 0.91744328019994\n",
            "\n",
            "[mbo] 74: min_sum_hessian_in_leaf=0.0231; learning_rate=0.0851; feature_fraction=0.255; bagging_fraction=0.587; lambda_l1=5.92; lambda_l2=2.5; min_gain_to_split=0.0654; bagging_freq=9; num_iterations=1476; max_depth=9; num_leaves=1987; min_data_in_leaf=4079 : y = 0.917 : 32.7 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:52:00 2025 AUC 0.92228974609546\n",
            "\n",
            "[mbo] 75: min_sum_hessian_in_leaf=0.0732; learning_rate=0.0517; feature_fraction=0.663; bagging_fraction=0.778; lambda_l1=0.133; lambda_l2=1.77; min_gain_to_split=0.144; bagging_freq=1; num_iterations=700; max_depth=10; num_leaves=2040; min_data_in_leaf=825 : y = 0.922 : 31.9 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:52:23 2025 AUC 0.921197595972634\n",
            "\n",
            "[mbo] 76: min_sum_hessian_in_leaf=0.0856; learning_rate=0.062; feature_fraction=0.468; bagging_fraction=0.966; lambda_l1=9.19; lambda_l2=3.14; min_gain_to_split=0.00715; bagging_freq=7; num_iterations=468; max_depth=14; num_leaves=1262; min_data_in_leaf=1078 : y = 0.921 : 20.7 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:52:33 2025 AUC 0.921723380704346\n",
            "\n",
            "[mbo] 77: min_sum_hessian_in_leaf=0.0902; learning_rate=0.0881; feature_fraction=0.877; bagging_fraction=0.503; lambda_l1=4.52; lambda_l2=3.69; min_gain_to_split=0.107; bagging_freq=9; num_iterations=337; max_depth=7; num_leaves=349; min_data_in_leaf=1088 : y = 0.922 : 8.3 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:53:06 2025 AUC 0.92330474791379\n",
            "\n",
            "[mbo] 78: min_sum_hessian_in_leaf=0.0927; learning_rate=0.0552; feature_fraction=0.788; bagging_fraction=0.888; lambda_l1=1.09; lambda_l2=2.76; min_gain_to_split=0.271; bagging_freq=6; num_iterations=1041; max_depth=8; num_leaves=1430; min_data_in_leaf=1405 : y = 0.923 : 31.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:53:54 2025 AUC 0.920675077124433\n",
            "\n",
            "[mbo] 79: min_sum_hessian_in_leaf=0.0228; learning_rate=0.0958; feature_fraction=0.583; bagging_fraction=0.743; lambda_l1=3.24; lambda_l2=2.9; min_gain_to_split=0.0908; bagging_freq=5; num_iterations=1550; max_depth=12; num_leaves=1012; min_data_in_leaf=4103 : y = 0.921 : 46.1 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:54:08 2025 AUC 0.919741624235662\n",
            "\n",
            "[mbo] 80: min_sum_hessian_in_leaf=0.0978; learning_rate=0.0282; feature_fraction=0.902; bagging_fraction=0.768; lambda_l1=1.54; lambda_l2=9.55; min_gain_to_split=2.41; bagging_freq=3; num_iterations=426; max_depth=-1; num_leaves=2014; min_data_in_leaf=422 : y = 0.92 : 12.3 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:55:01 2025 AUC 0.9224407756483\n",
            "\n",
            "[mbo] 81: min_sum_hessian_in_leaf=0.00476; learning_rate=0.0772; feature_fraction=0.62; bagging_fraction=0.924; lambda_l1=8.74; lambda_l2=0.42; min_gain_to_split=0.0665; bagging_freq=10; num_iterations=2333; max_depth=13; num_leaves=649; min_data_in_leaf=3477 : y = 0.922 : 51.0 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:55:27 2025 AUC 0.910090982632015\n",
            "\n",
            "[mbo] 82: min_sum_hessian_in_leaf=0.0137; learning_rate=0.0305; feature_fraction=0.643; bagging_fraction=0.62; lambda_l1=3.7; lambda_l2=5.53; min_gain_to_split=0.735; bagging_freq=4; num_iterations=1129; max_depth=13; num_leaves=1588; min_data_in_leaf=6360 : y = 0.91 : 23.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:55:51 2025 AUC 0.924382933705399\n",
            "\n",
            "[mbo] 83: min_sum_hessian_in_leaf=0.0828; learning_rate=0.0265; feature_fraction=0.976; bagging_fraction=0.861; lambda_l1=7.89; lambda_l2=5.01; min_gain_to_split=0.0406; bagging_freq=1; num_iterations=660; max_depth=6; num_leaves=993; min_data_in_leaf=90 : y = 0.924 : 22.0 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:56:17 2025 AUC 0.91405116157526\n",
            "\n",
            "[mbo] 84: min_sum_hessian_in_leaf=0.0331; learning_rate=0.0243; feature_fraction=0.572; bagging_fraction=0.974; lambda_l1=8.74; lambda_l2=3.9; min_gain_to_split=1.96; bagging_freq=6; num_iterations=851; max_depth=13; num_leaves=1355; min_data_in_leaf=4655 : y = 0.914 : 24.6 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:57:03 2025 AUC 0.922493974936001\n",
            "\n",
            "[mbo] 85: min_sum_hessian_in_leaf=0.0633; learning_rate=0.0712; feature_fraction=0.918; bagging_fraction=0.817; lambda_l1=9.85; lambda_l2=0.946; min_gain_to_split=0.0734; bagging_freq=9; num_iterations=2485; max_depth=12; num_leaves=259; min_data_in_leaf=123 : y = 0.922 : 43.7 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:57:16 2025 AUC 0.921523752690545\n",
            "\n",
            "[mbo] 86: min_sum_hessian_in_leaf=0.0916; learning_rate=0.0675; feature_fraction=0.978; bagging_fraction=0.797; lambda_l1=9.82; lambda_l2=0.561; min_gain_to_split=0.177; bagging_freq=8; num_iterations=609; max_depth=6; num_leaves=423; min_data_in_leaf=2487 : y = 0.922 : 11.4 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:57:41 2025 AUC 0.918268794292823\n",
            "\n",
            "[mbo] 87: min_sum_hessian_in_leaf=0.0707; learning_rate=0.0697; feature_fraction=0.694; bagging_fraction=0.908; lambda_l1=9.49; lambda_l2=0.457; min_gain_to_split=2.18; bagging_freq=4; num_iterations=1995; max_depth=7; num_leaves=527; min_data_in_leaf=990 : y = 0.918 : 22.9 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:58:09 2025 AUC 0.916097060022256\n",
            "\n",
            "[mbo] 88: min_sum_hessian_in_leaf=0.0987; learning_rate=0.0421; feature_fraction=0.968; bagging_fraction=0.484; lambda_l1=3.98; lambda_l2=3.27; min_gain_to_split=5.86; bagging_freq=5; num_iterations=2960; max_depth=7; num_leaves=528; min_data_in_leaf=842 : y = 0.916 : 26.3 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:58:38 2025 AUC 0.924170271267473\n",
            "\n",
            "[mbo] 89: min_sum_hessian_in_leaf=0.0393; learning_rate=0.0639; feature_fraction=0.963; bagging_fraction=0.829; lambda_l1=5.01; lambda_l2=0.865; min_gain_to_split=0.00586; bagging_freq=9; num_iterations=919; max_depth=9; num_leaves=796; min_data_in_leaf=857 : y = 0.924 : 27.1 secs : infill_ei\n",
            "\n",
            "jue sept 11 16:59:18 2025 AUC 0.917349229503904\n",
            "\n",
            "[mbo] 90: min_sum_hessian_in_leaf=0.052; learning_rate=0.0724; feature_fraction=0.568; bagging_fraction=0.805; lambda_l1=8.55; lambda_l2=0.279; min_gain_to_split=0.0911; bagging_freq=10; num_iterations=1746; max_depth=14; num_leaves=305; min_data_in_leaf=5689 : y = 0.917 : 37.9 secs : infill_ei\n",
            "\n",
            "jue sept 11 17:00:13 2025 AUC 0.923320925039369\n",
            "\n",
            "[mbo] 91: min_sum_hessian_in_leaf=0.0676; learning_rate=0.0643; feature_fraction=0.951; bagging_fraction=0.649; lambda_l1=0.463; lambda_l2=3.8; min_gain_to_split=0.0733; bagging_freq=8; num_iterations=1044; max_depth=10; num_leaves=564; min_data_in_leaf=189 : y = 0.923 : 53.1 secs : infill_ei\n",
            "\n",
            "jue sept 11 17:01:00 2025 AUC 0.921406951037487\n",
            "\n",
            "[mbo] 92: min_sum_hessian_in_leaf=0.00129; learning_rate=0.0808; feature_fraction=0.37; bagging_fraction=0.706; lambda_l1=6.49; lambda_l2=1.74; min_gain_to_split=1.53; bagging_freq=10; num_iterations=2791; max_depth=5; num_leaves=176; min_data_in_leaf=701 : y = 0.921 : 44.8 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 93 in the file bayesiana.RDATA.\n",
            "\n",
            "jue sept 11 17:02:20 2025 AUC 0.924450677865222\n",
            "\n",
            "[mbo] 93: min_sum_hessian_in_leaf=0.00683; learning_rate=0.0168; feature_fraction=0.842; bagging_fraction=0.76; lambda_l1=5.41; lambda_l2=0.566; min_gain_to_split=0.191; bagging_freq=2; num_iterations=2793; max_depth=5; num_leaves=1044; min_data_in_leaf=135 : y = 0.924 : 77.8 secs : infill_ei\n",
            "\n",
            "jue sept 11 17:04:31 2025 AUC 0.924835380200862\n",
            "\n",
            "[mbo] 94: min_sum_hessian_in_leaf=0.0263; learning_rate=0.031; feature_fraction=0.845; bagging_fraction=0.71; lambda_l1=1.43; lambda_l2=2.93; min_gain_to_split=0.0782; bagging_freq=5; num_iterations=2166; max_depth=9; num_leaves=1870; min_data_in_leaf=4 : y = 0.925 : 129.5 secs : infill_ei\n",
            "\n",
            "jue sept 11 17:05:28 2025 AUC 0.922281473709018\n",
            "\n",
            "[mbo] 95: min_sum_hessian_in_leaf=0.0129; learning_rate=0.0194; feature_fraction=0.894; bagging_fraction=0.748; lambda_l1=8.97; lambda_l2=3.42; min_gain_to_split=0.101; bagging_freq=9; num_iterations=2934; max_depth=12; num_leaves=482; min_data_in_leaf=2099 : y = 0.922 : 54.9 secs : infill_ei\n",
            "\n",
            "jue sept 11 17:06:02 2025 AUC 0.924907413972722\n",
            "\n",
            "[mbo] 96: min_sum_hessian_in_leaf=0.0946; learning_rate=0.0506; feature_fraction=0.998; bagging_fraction=0.749; lambda_l1=3.9; lambda_l2=2.39; min_gain_to_split=0.0326; bagging_freq=2; num_iterations=1609; max_depth=2; num_leaves=502; min_data_in_leaf=260 : y = 0.925 : 31.9 secs : infill_ei\n",
            "\n",
            "jue sept 11 17:07:07 2025 AUC 0.920875725682966\n",
            "\n",
            "[mbo] 97: min_sum_hessian_in_leaf=0.0109; learning_rate=0.0851; feature_fraction=0.993; bagging_fraction=0.77; lambda_l1=1.52; lambda_l2=0.266; min_gain_to_split=0.111; bagging_freq=9; num_iterations=2994; max_depth=12; num_leaves=262; min_data_in_leaf=3275 : y = 0.921 : 63.0 secs : infill_ei\n",
            "\n",
            "jue sept 11 17:08:17 2025 AUC 0.923721685184361\n",
            "\n",
            "[mbo] 98: min_sum_hessian_in_leaf=0.0999; learning_rate=0.0118; feature_fraction=0.803; bagging_fraction=0.809; lambda_l1=8.59; lambda_l2=2.33; min_gain_to_split=0.0921; bagging_freq=3; num_iterations=2223; max_depth=7; num_leaves=1847; min_data_in_leaf=107 : y = 0.924 : 68.6 secs : infill_ei\n",
            "\n",
            "jue sept 11 17:09:02 2025 AUC 0.923671281403697\n",
            "\n",
            "[mbo] 99: min_sum_hessian_in_leaf=0.066; learning_rate=0.0604; feature_fraction=0.869; bagging_fraction=0.705; lambda_l1=6.8; lambda_l2=0.129; min_gain_to_split=0.148; bagging_freq=7; num_iterations=2313; max_depth=6; num_leaves=345; min_data_in_leaf=1091 : y = 0.924 : 42.4 secs : infill_ei\n",
            "\n",
            "jue sept 11 17:09:36 2025 AUC 0.923589801657471\n",
            "\n",
            "[mbo] 100: min_sum_hessian_in_leaf=0.0848; learning_rate=0.0512; feature_fraction=0.771; bagging_fraction=0.798; lambda_l1=5.34; lambda_l2=5.46; min_gain_to_split=0.0811; bagging_freq=4; num_iterations=1200; max_depth=5; num_leaves=1514; min_data_in_leaf=375 : y = 0.924 : 32.9 secs : infill_ei\n",
            "\n",
            "Saved the final state in the file bayesiana.RDATA\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# inicio la optimizacion bayesiana, retomando si ya existe\n",
        "# es la celda mas lenta de todo el notebook\n",
        "\n",
        "if (!file.exists(kbayesiana)) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ssk5nnMk6INK",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'min_sum_hessian_in_leaf'</li><li>'learning_rate'</li><li>'feature_fraction'</li><li>'bagging_fraction'</li><li>'lambda_l1'</li><li>'lambda_l2'</li><li>'min_gain_to_split'</li><li>'bagging_freq'</li><li>'num_iterations'</li><li>'max_depth'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 'min\\_sum\\_hessian\\_in\\_leaf'\n",
              "\\item 'learning\\_rate'\n",
              "\\item 'feature\\_fraction'\n",
              "\\item 'bagging\\_fraction'\n",
              "\\item 'lambda\\_l1'\n",
              "\\item 'lambda\\_l2'\n",
              "\\item 'min\\_gain\\_to\\_split'\n",
              "\\item 'bagging\\_freq'\n",
              "\\item 'num\\_iterations'\n",
              "\\item 'max\\_depth'\n",
              "\\item 'num\\_leaves'\n",
              "\\item 'min\\_data\\_in\\_leaf'\n",
              "\\item 'y'\n",
              "\\item 'dob'\n",
              "\\item 'eol'\n",
              "\\item 'error.message'\n",
              "\\item 'exec.time'\n",
              "\\item 'ei'\n",
              "\\item 'error.model'\n",
              "\\item 'train.time'\n",
              "\\item 'prop.type'\n",
              "\\item 'propose.time'\n",
              "\\item 'se'\n",
              "\\item 'mean'\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 'min_sum_hessian_in_leaf'\n",
              "2. 'learning_rate'\n",
              "3. 'feature_fraction'\n",
              "4. 'bagging_fraction'\n",
              "5. 'lambda_l1'\n",
              "6. 'lambda_l2'\n",
              "7. 'min_gain_to_split'\n",
              "8. 'bagging_freq'\n",
              "9. 'num_iterations'\n",
              "10. 'max_depth'\n",
              "11. 'num_leaves'\n",
              "12. 'min_data_in_leaf'\n",
              "13. 'y'\n",
              "14. 'dob'\n",
              "15. 'eol'\n",
              "16. 'error.message'\n",
              "17. 'exec.time'\n",
              "18. 'ei'\n",
              "19. 'error.model'\n",
              "20. 'train.time'\n",
              "21. 'prop.type'\n",
              "22. 'propose.time'\n",
              "23. 'se'\n",
              "24. 'mean'\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              " [1] \"min_sum_hessian_in_leaf\" \"learning_rate\"          \n",
              " [3] \"feature_fraction\"        \"bagging_fraction\"       \n",
              " [5] \"lambda_l1\"               \"lambda_l2\"              \n",
              " [7] \"min_gain_to_split\"       \"bagging_freq\"           \n",
              " [9] \"num_iterations\"          \"max_depth\"              \n",
              "[11] \"num_leaves\"              \"min_data_in_leaf\"       \n",
              "[13] \"y\"                       \"dob\"                    \n",
              "[15] \"eol\"                     \"error.message\"          \n",
              "[17] \"exec.time\"               \"ei\"                     \n",
              "[19] \"error.model\"             \"train.time\"             \n",
              "[21] \"prop.type\"               \"propose.time\"           \n",
              "[23] \"se\"                      \"mean\"                   "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "colnames( tb_bayesiana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "u4zq-vknhjGc",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "tb_bayesiana[, iter := .I]\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file= \"BO_log.txt\",\n",
        "  sep= \"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  setdiff(colnames(tb_bayesiana),\n",
        "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
        "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
        "  with= FALSE\n",
        "]\n",
        "\n",
        "\n",
        "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "E8v2eA427N8e",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iBTWexVU7PGC",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   min_sum_hessian_in_leaf learning_rate feature_fraction bagging_fraction\n",
            "                     <num>         <num>            <num>            <num>\n",
            "1:              0.09456982    0.05058265        0.9983571        0.7486183\n",
            "   lambda_l1 lambda_l2 min_gain_to_split bagging_freq num_iterations max_depth\n",
            "       <num>     <num>             <num>        <int>          <int>     <int>\n",
            "1:  3.896823  2.389017        0.03257132            2           1609         2\n",
            "   num_leaves min_data_in_leaf\n",
            "        <int>            <int>\n",
            "1:        502              260\n",
            "[1] 0.9249074\n"
          ]
        }
      ],
      "source": [
        "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
        "print(PARAM$out$lgbm$y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKsVZmAnhwX-"
      },
      "source": [
        "## 2.3  Produccion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ_C33Tr5B_9"
      },
      "source": [
        "### Final Training\n",
        "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qFmFivf5Iet"
      },
      "source": [
        "#### Final Training Dataset\n",
        "\n",
        "Aqui esta la gran decision de en qué meses hago el Final Training\n",
        "<br> debo utilizar los mejores hiperparámetros que encontré en la  optimización bayesiana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lg5WVZncvc7H",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# clase01\n",
        "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yc9QzXREv0xf",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.table: 3 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>clase_ternaria</th><th scope=col>N</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>CONTINUA</td><td>160292</td></tr>\n",
              "\t<tr><td>BAJA+1  </td><td>   831</td></tr>\n",
              "\t<tr><td>BAJA+2  </td><td>  1032</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A data.table: 3 × 2\n",
              "\\begin{tabular}{ll}\n",
              " clase\\_ternaria & N\\\\\n",
              " <fct> & <int>\\\\\n",
              "\\hline\n",
              "\t CONTINUA & 160292\\\\\n",
              "\t BAJA+1   &    831\\\\\n",
              "\t BAJA+2   &   1032\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A data.table: 3 × 2\n",
              "\n",
              "| clase_ternaria &lt;fct&gt; | N &lt;int&gt; |\n",
              "|---|---|\n",
              "| CONTINUA | 160292 |\n",
              "| BAJA+1   |    831 |\n",
              "| BAJA+2   |   1032 |\n",
              "\n"
            ],
            "text/plain": [
              "  clase_ternaria N     \n",
              "1 CONTINUA       160292\n",
              "2 BAJA+1            831\n",
              "3 BAJA+2           1032"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset_train <- dataset[foto_mes %in% PARAM$train_final]\n",
        "dataset_train[,.N,clase_ternaria]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "thjdqEBLuvNt",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain_final <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[, clase01]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNUa-WSz5Oqu"
      },
      "source": [
        "#### Final Training Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FgCcvBfEwImu",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$boosting</dt>\n",
              "\t\t<dd>'gbdt'</dd>\n",
              "\t<dt>$objective</dt>\n",
              "\t\t<dd>'binary'</dd>\n",
              "\t<dt>$metric</dt>\n",
              "\t\t<dd>'auc'</dd>\n",
              "\t<dt>$first_metric_only</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$boost_from_average</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$feature_pre_filter</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$force_row_wise</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$verbosity</dt>\n",
              "\t\t<dd>-100</dd>\n",
              "\t<dt>$seed</dt>\n",
              "\t\t<dd>200003</dd>\n",
              "\t<dt>$max_depth</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>$min_gain_to_split</dt>\n",
              "\t\t<dd>0.0325713219948005</dd>\n",
              "\t<dt>$min_sum_hessian_in_leaf</dt>\n",
              "\t\t<dd>0.0945698224853425</dd>\n",
              "\t<dt>$lambda_l1</dt>\n",
              "\t\t<dd>3.89682298062122</dd>\n",
              "\t<dt>$lambda_l2</dt>\n",
              "\t\t<dd>2.38901746980235</dd>\n",
              "\t<dt>$max_bin</dt>\n",
              "\t\t<dd>31</dd>\n",
              "\t<dt>$bagging_fraction</dt>\n",
              "\t\t<dd>0.748618283170503</dd>\n",
              "\t<dt>$pos_bagging_fraction</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$neg_bagging_fraction</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$is_unbalance</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$scale_pos_weight</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$drop_rate</dt>\n",
              "\t\t<dd>0.1</dd>\n",
              "\t<dt>$max_drop</dt>\n",
              "\t\t<dd>50</dd>\n",
              "\t<dt>$skip_drop</dt>\n",
              "\t\t<dd>0.5</dd>\n",
              "\t<dt>$extra_trees</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$num_iterations</dt>\n",
              "\t\t<dd>1609</dd>\n",
              "\t<dt>$learning_rate</dt>\n",
              "\t\t<dd>0.0505826454144719</dd>\n",
              "\t<dt>$feature_fraction</dt>\n",
              "\t\t<dd>0.998357089257255</dd>\n",
              "\t<dt>$num_leaves</dt>\n",
              "\t\t<dd>502</dd>\n",
              "\t<dt>$min_data_in_leaf</dt>\n",
              "\t\t<dd>260</dd>\n",
              "\t<dt>$bagging_freq</dt>\n",
              "\t\t<dd>2</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$boosting] 'gbdt'\n",
              "\\item[\\$objective] 'binary'\n",
              "\\item[\\$metric] 'auc'\n",
              "\\item[\\$first\\_metric\\_only] FALSE\n",
              "\\item[\\$boost\\_from\\_average] TRUE\n",
              "\\item[\\$feature\\_pre\\_filter] FALSE\n",
              "\\item[\\$force\\_row\\_wise] TRUE\n",
              "\\item[\\$verbosity] -100\n",
              "\\item[\\$seed] 200003\n",
              "\\item[\\$max\\_depth] 2\n",
              "\\item[\\$min\\_gain\\_to\\_split] 0.0325713219948005\n",
              "\\item[\\$min\\_sum\\_hessian\\_in\\_leaf] 0.0945698224853425\n",
              "\\item[\\$lambda\\_l1] 3.89682298062122\n",
              "\\item[\\$lambda\\_l2] 2.38901746980235\n",
              "\\item[\\$max\\_bin] 31\n",
              "\\item[\\$bagging\\_fraction] 0.748618283170503\n",
              "\\item[\\$pos\\_bagging\\_fraction] 1\n",
              "\\item[\\$neg\\_bagging\\_fraction] 1\n",
              "\\item[\\$is\\_unbalance] FALSE\n",
              "\\item[\\$scale\\_pos\\_weight] 1\n",
              "\\item[\\$drop\\_rate] 0.1\n",
              "\\item[\\$max\\_drop] 50\n",
              "\\item[\\$skip\\_drop] 0.5\n",
              "\\item[\\$extra\\_trees] TRUE\n",
              "\\item[\\$num\\_iterations] 1609\n",
              "\\item[\\$learning\\_rate] 0.0505826454144719\n",
              "\\item[\\$feature\\_fraction] 0.998357089257255\n",
              "\\item[\\$num\\_leaves] 502\n",
              "\\item[\\$min\\_data\\_in\\_leaf] 260\n",
              "\\item[\\$bagging\\_freq] 2\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$boosting\n",
              ":   'gbdt'\n",
              "$objective\n",
              ":   'binary'\n",
              "$metric\n",
              ":   'auc'\n",
              "$first_metric_only\n",
              ":   FALSE\n",
              "$boost_from_average\n",
              ":   TRUE\n",
              "$feature_pre_filter\n",
              ":   FALSE\n",
              "$force_row_wise\n",
              ":   TRUE\n",
              "$verbosity\n",
              ":   -100\n",
              "$seed\n",
              ":   200003\n",
              "$max_depth\n",
              ":   2\n",
              "$min_gain_to_split\n",
              ":   0.0325713219948005\n",
              "$min_sum_hessian_in_leaf\n",
              ":   0.0945698224853425\n",
              "$lambda_l1\n",
              ":   3.89682298062122\n",
              "$lambda_l2\n",
              ":   2.38901746980235\n",
              "$max_bin\n",
              ":   31\n",
              "$bagging_fraction\n",
              ":   0.748618283170503\n",
              "$pos_bagging_fraction\n",
              ":   1\n",
              "$neg_bagging_fraction\n",
              ":   1\n",
              "$is_unbalance\n",
              ":   FALSE\n",
              "$scale_pos_weight\n",
              ":   1\n",
              "$drop_rate\n",
              ":   0.1\n",
              "$max_drop\n",
              ":   50\n",
              "$skip_drop\n",
              ":   0.5\n",
              "$extra_trees\n",
              ":   TRUE\n",
              "$num_iterations\n",
              ":   1609\n",
              "$learning_rate\n",
              ":   0.0505826454144719\n",
              "$feature_fraction\n",
              ":   0.998357089257255\n",
              "$num_leaves\n",
              ":   502\n",
              "$min_data_in_leaf\n",
              ":   260\n",
              "$bagging_freq\n",
              ":   2\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$boosting\n",
              "[1] \"gbdt\"\n",
              "\n",
              "$objective\n",
              "[1] \"binary\"\n",
              "\n",
              "$metric\n",
              "[1] \"auc\"\n",
              "\n",
              "$first_metric_only\n",
              "[1] FALSE\n",
              "\n",
              "$boost_from_average\n",
              "[1] TRUE\n",
              "\n",
              "$feature_pre_filter\n",
              "[1] FALSE\n",
              "\n",
              "$force_row_wise\n",
              "[1] TRUE\n",
              "\n",
              "$verbosity\n",
              "[1] -100\n",
              "\n",
              "$seed\n",
              "[1] 200003\n",
              "\n",
              "$max_depth\n",
              "[1] 2\n",
              "\n",
              "$min_gain_to_split\n",
              "[1] 0.03257132\n",
              "\n",
              "$min_sum_hessian_in_leaf\n",
              "[1] 0.09456982\n",
              "\n",
              "$lambda_l1\n",
              "[1] 3.896823\n",
              "\n",
              "$lambda_l2\n",
              "[1] 2.389017\n",
              "\n",
              "$max_bin\n",
              "[1] 31\n",
              "\n",
              "$bagging_fraction\n",
              "[1] 0.7486183\n",
              "\n",
              "$pos_bagging_fraction\n",
              "[1] 1\n",
              "\n",
              "$neg_bagging_fraction\n",
              "[1] 1\n",
              "\n",
              "$is_unbalance\n",
              "[1] FALSE\n",
              "\n",
              "$scale_pos_weight\n",
              "[1] 1\n",
              "\n",
              "$drop_rate\n",
              "[1] 0.1\n",
              "\n",
              "$max_drop\n",
              "[1] 50\n",
              "\n",
              "$skip_drop\n",
              "[1] 0.5\n",
              "\n",
              "$extra_trees\n",
              "[1] TRUE\n",
              "\n",
              "$num_iterations\n",
              "[1] 1609\n",
              "\n",
              "$learning_rate\n",
              "[1] 0.05058265\n",
              "\n",
              "$feature_fraction\n",
              "[1] 0.9983571\n",
              "\n",
              "$num_leaves\n",
              "[1] 502\n",
              "\n",
              "$min_data_in_leaf\n",
              "[1] 260\n",
              "\n",
              "$bagging_freq\n",
              "[1] 2\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
        "  PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "param_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZIYn4l95TBH"
      },
      "source": [
        "#### Training\n",
        "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria y mucho menos cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vPLsd4mMRe4u",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
        "\n",
        "param_normalizado <- copy(param_final)\n",
        "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "WRI_-taRwOXO",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# entreno LightGBM\n",
        "\n",
        "modelo_final <- lgb.train(\n",
        "  data= dtrain_final,\n",
        "  param= param_normalizado\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_bkhnCvj0g3Q",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "\n",
        "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite(tb_importancia,\n",
        "  file= archivo_importancia,\n",
        "  sep= \"\\t\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lZ3sLmbh0kFj",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "lgb.save(modelo_final, \"modelo.txt\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEtp2--t5Ymg"
      },
      "source": [
        "### Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI5008Mj5ZdI"
      },
      "source": [
        "Aplico el modelo final a los datos del futuro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PimBY3N_0ryP",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# aplico el modelo a los datos sin clase\n",
        "dfuture <- dataset[foto_mes %in% PARAM$future]\n",
        "\n",
        "# aplico el modelo a los datos nuevos\n",
        "prediccion <- predict(\n",
        "  modelo_final,\n",
        "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "M9_NCquymhtF",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# inicilizo el dataset  drealidad\n",
        "drealidad <- realidad_inicializar( dfuture, PARAM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D26rNRh55gpw"
      },
      "source": [
        "#### Tabla Prediccion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RJwg7LHd11yu",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# tabla de prediccion\n",
        "\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
        "tb_prediccion[, prob := prediccion ]\n",
        "\n",
        "# grabo las probabilidad del modelo\n",
        "fwrite(tb_prediccion,\n",
        "  file= \"prediccion.txt\",\n",
        "  sep= \"\\t\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOt4eG_55ltv"
      },
      "source": [
        "Kaggle Competition Submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Vdu3moTfJ1Vl",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>6000</li><li>6500</li><li>7000</li><li>7500</li><li>8000</li><li>8500</li><li>9000</li><li>9500</li><li>10000</li><li>10500</li><li>11000</li><li>11500</li><li>12000</li><li>12500</li><li>13000</li><li>13500</li><li>14000</li><li>14500</li><li>15000</li><li>15500</li><li>16000</li><li>16500</li><li>17000</li><li>17500</li><li>18000</li><li>18500</li><li>19000</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 6000\n",
              "\\item 6500\n",
              "\\item 7000\n",
              "\\item 7500\n",
              "\\item 8000\n",
              "\\item 8500\n",
              "\\item 9000\n",
              "\\item 9500\n",
              "\\item 10000\n",
              "\\item 10500\n",
              "\\item 11000\n",
              "\\item 11500\n",
              "\\item 12000\n",
              "\\item 12500\n",
              "\\item 13000\n",
              "\\item 13500\n",
              "\\item 14000\n",
              "\\item 14500\n",
              "\\item 15000\n",
              "\\item 15500\n",
              "\\item 16000\n",
              "\\item 16500\n",
              "\\item 17000\n",
              "\\item 17500\n",
              "\\item 18000\n",
              "\\item 18500\n",
              "\\item 19000\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 6000\n",
              "2. 6500\n",
              "3. 7000\n",
              "4. 7500\n",
              "5. 8000\n",
              "6. 8500\n",
              "7. 9000\n",
              "8. 9500\n",
              "9. 10000\n",
              "10. 10500\n",
              "11. 11000\n",
              "12. 11500\n",
              "13. 12000\n",
              "14. 12500\n",
              "15. 13000\n",
              "16. 13500\n",
              "17. 14000\n",
              "18. 14500\n",
              "19. 15000\n",
              "20. 15500\n",
              "21. 16000\n",
              "22. 16500\n",
              "23. 17000\n",
              "24. 17500\n",
              "25. 18000\n",
              "26. 18500\n",
              "27. 19000\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              " [1]  6000  6500  7000  7500  8000  8500  9000  9500 10000 10500 11000 11500\n",
              "[13] 12000 12500 13000 13500 14000 14500 15000 15500 16000 16500 17000 17500\n",
              "[25] 18000 18500 19000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "PARAM$cortes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gWW3tatE12je",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Envios=6000\t TOTAL=334400000  Public=288200000 Private=354200000\n",
            "Envios=6500\t TOTAL=341200000  Public=304333333 Private=357000000\n",
            "Envios=7000\t TOTAL=346400000  Public=312733333 Private=360828571\n",
            "Envios=7500\t TOTAL=348400000  Public=316666667 Private=362000000\n",
            "Envios=8000\t TOTAL=351200000  Public=314733333 Private=366828571\n",
            "Envios=8500\t TOTAL=354800000  Public=323600000 Private=368171429\n",
            "Envios=9000\t TOTAL=353600000  Public=321400000 Private=367400000\n",
            "Envios=9500\t TOTAL=358000000  Public=323866667 Private=372628571\n",
            "Envios=10000\t TOTAL=352800000  Public=321733333 Private=366114286\n",
            "Envios=10500\t TOTAL=354800000  Public=322533333 Private=368628571\n",
            "Envios=11000\t TOTAL=357600000  Public=325666667 Private=371285714\n",
            "Envios=11500\t TOTAL=356400000  Public=320333333 Private=371857143\n",
            "Envios=12000\t TOTAL=350400000  Public=310200000 Private=367628571\n",
            "Envios=12500\t TOTAL=349200000  Public=310666667 Private=365714286\n",
            "Envios=13000\t TOTAL=347200000  Public=308333333 Private=363857143\n",
            "Envios=13500\t TOTAL=344400000  Public=305466667 Private=361085714\n",
            "Envios=14000\t TOTAL=344800000  Public=311533333 Private=359057143\n",
            "Envios=14500\t TOTAL=341200000  Public=306266667 Private=356171429\n",
            "Envios=15000\t TOTAL=339200000  Public=309466667 Private=351942857\n",
            "Envios=15500\t TOTAL=332400000  Public=297866667 Private=347200000\n",
            "Envios=16000\t TOTAL=325600000  Public=291200000 Private=340342857\n",
            "Envios=16500\t TOTAL=318800000  Public=288600000 Private=331742857\n",
            "Envios=17000\t TOTAL=314400000  Public=291266667 Private=324314286\n",
            "Envios=17500\t TOTAL=309200000  Public=287000000 Private=318714286\n",
            "Envios=18000\t TOTAL=302400000  Public=277933333 Private=312885714\n",
            "Envios=18500\t TOTAL=296400000  Public=271800000 Private=306942857\n",
            "Envios=19000\t TOTAL=289600000  Public=265666667 Private=299857143\n"
          ]
        }
      ],
      "source": [
        "# genero archivos con los  \"envios\" mejores\n",
        "# suba TODOS los archivos a Kaggle\n",
        "\n",
        "# ordeno por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "dir.create(\"kaggle\")\n",
        "\n",
        "for (envios in PARAM$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marco los primeros\n",
        "\n",
        "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "\n",
        "  # grabo el archivo\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "    file= archivo_kaggle,\n",
        "    sep= \",\"\n",
        "  )\n",
        "\n",
        "  res <- realidad_evaluar( drealidad, tb_prediccion)\n",
        "\n",
        "  options(scipen = 999)\n",
        "  cat( \"Envios=\", envios, \"\\t\",\n",
        "    \" TOTAL=\", res$total,\n",
        "    \"  Public=\", res$public,\n",
        "    \" Private=\", res$private,\n",
        "    \"\\n\",\n",
        "    sep= \"\"\n",
        "  )\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "B9tB2X4439Hg",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9zA_W25c15DP",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "'jue sept 11 17:09:53 2025'"
            ],
            "text/latex": [
              "'jue sept 11 17:09:53 2025'"
            ],
            "text/markdown": [
              "'jue sept 11 17:09:53 2025'"
            ],
            "text/plain": [
              "[1] \"jue sept 11 17:09:53 2025\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVZucdLHzZ0"
      },
      "source": [
        "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
        "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Envios=6000\t TOTAL=336000000  Public=294066667 Private=353971429\n",
            "Envios=6500\t TOTAL=340400000  Public=307133333 Private=354657143\n",
            "Envios=7000\t TOTAL=344000000  Public=310133333 Private=358514286\n",
            "Envios=7500\t TOTAL=348400000  Public=315266667 Private=362600000\n",
            "Envios=8000\t TOTAL=352000000  Public=314933333 Private=367885714\n",
            "Envios=8500\t TOTAL=359600000  Public=326266667 Private=373885714\n",
            "Envios=9000\t TOTAL=363200000  Public=334800000 Private=375371429\n",
            "Envios=9500\t TOTAL=362800000  Public=335400000 Private=374542857\n",
            "Envios=10000\t TOTAL=360000000  Public=327466667 Private=373942857\n",
            "Envios=10500\t TOTAL=358800000  Public=324600000 Private=373457143\n",
            "Envios=11000\t TOTAL=356800000  Public=328066667 Private=369114286\n",
            "Envios=11500\t TOTAL=355600000  Public=323200000 Private=369485714\n",
            "Envios=12000\t TOTAL=351200000  Public=315000000 Private=366714286\n",
            "Envios=12500\t TOTAL=346800000  Public=310800000 Private=362228571\n",
            "Envios=13000\t TOTAL=348000000  Public=311533333 Private=363628571\n",
            "Envios=13500\t TOTAL=344400000  Public=308733333 Private=359685714\n",
            "Envios=14000\t TOTAL=340800000  Public=309933333 Private=354028571\n",
            "Envios=14500\t TOTAL=335600000  Public=299333333 Private=351142857\n",
            "Envios=15000\t TOTAL=334400000  Public=307333333 Private=346000000\n",
            "Envios=15500\t TOTAL=330000000  Public=303000000 Private=341571429\n",
            "Envios=16000\t TOTAL=326400000  Public=300533333 Private=337485714\n",
            "Envios=16500\t TOTAL=318800000  Public=294266667 Private=329314286\n",
            "Envios=17000\t TOTAL=312000000  Public=286733333 Private=322828571\n",
            "Envios=17500\t TOTAL=306800000  Public=284533333 Private=316342857\n",
            "Envios=18000\t TOTAL=302400000  Public=279133333 Private=312371429\n",
            "Envios=18500\t TOTAL=295600000  Public=272600000 Private=305457143\n",
            "Envios=19000\t TOTAL=292000000  Public=262600000 Private=304600000\n"
          ]
        }
      ],
      "source": [
        "# Definir las 5 semillas fijas para el ensemble\n",
        "semillas_fijas <- c(200003,300007,400009,500009,600011)\n",
        "\n",
        "# Inicializar una lista para almacenar las predicciones de cada modelo\n",
        "list_predicciones <- list()\n",
        "\n",
        "# Iniciar el bucle para entrenar y predecir con cada una de las semillas\n",
        "for (semilla in semillas_fijas) {\n",
        "\n",
        "  # Asignar la semilla actual a los parámetros del modelo\n",
        "  param_normalizado$seed <- semilla\n",
        "  \n",
        "  # Entrenar el modelo LightGBM\n",
        "  modelo_temp <- lgb.train(\n",
        "    data = dtrain_final,\n",
        "    param = param_normalizado\n",
        "  )\n",
        "  \n",
        "  # Preparar los datos sin clase para la predicción\n",
        "  dfuture <- dataset[foto_mes %in% PARAM$future]\n",
        "  \n",
        "  # Realizar la predicción con el modelo actual\n",
        "  prediccion_temp <- predict(\n",
        "    modelo_temp,\n",
        "    data.matrix(dfuture[, campos_buenos, with = FALSE])\n",
        "  )\n",
        "  \n",
        "  # Guardar la predicción en la lista\n",
        "  list_predicciones[[length(list_predicciones) + 1]] <- prediccion_temp\n",
        "}\n",
        "\n",
        "# Unir las predicciones de todos los modelos en una sola matriz\n",
        "matriz_predicciones <- do.call(cbind, list_predicciones)\n",
        "\n",
        "# Calcular el promedio de las predicciones para obtener el resultado final del ensemble\n",
        "prediccion_ensemble <- rowMeans(matriz_predicciones)\n",
        "\n",
        "# Ahora, la variable 'prediccion_ensemble' contiene el resultado final del ensemble.\n",
        "# A partir de aquí, el código continúa usando esta nueva variable.\n",
        "\n",
        "# Inicilizo el dataset drealidad\n",
        "drealidad <- realidad_inicializar( dfuture, PARAM)\n",
        "\n",
        "# Crear la tabla de predicción\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
        "tb_prediccion[, prob := prediccion_ensemble ]\n",
        "\n",
        "# Generar los \"envios\" para los mejores resultados\n",
        "# Ordenar por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "# Crear el directorio 'kaggle' si no existe\n",
        "dir.create(\"kaggle_promediado\")\n",
        "\n",
        "for (envios in PARAM$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marcar los primeros envíos\n",
        "  \n",
        "  # Nombre del archivo para Kaggle\n",
        "  archivo_kaggle <- paste0(\"./kaggle_promediado/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "  \n",
        "  # Guardar el archivo CSV\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "         file = archivo_kaggle,\n",
        "         sep = \",\"\n",
        "  )\n",
        "  \n",
        "  # Evaluar el resultado\n",
        "  res <- realidad_evaluar( drealidad, tb_prediccion)\n",
        "  \n",
        "  # Imprimir los resultados en la consola\n",
        "  options(scipen = 999)\n",
        "  cat( \"Envios=\", envios, \"\\t\",\n",
        "       \" TOTAL=\", res$total,\n",
        "       \"  Public=\", res$public,\n",
        "       \" Private=\", res$private,\n",
        "       \"\\n\",\n",
        "       sep= \"\"\n",
        "  )\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
